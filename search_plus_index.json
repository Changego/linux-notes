{"./":{"url":"./","title":"前言","keywords":"","body":"linux-notes Linux 学习笔记 Summary 前言 Linux 文件系统 Linux 介绍 Linux 文件权限 Shell 脚本 Shell简介 运维工具 Ansible的使用 Supervisor的使用 Confd的使用 NFS的使用 Git Git 介绍 Git 常用命令 Git 命令分类 Nginx Nginx安装与配置 Nginx作为反向代理 Nginx http服务器 Keepalived Keepalived简介 Keepalived的安装与配置 Keepalived的配置详解 Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-09-23 20:56:23 "},"file/linux-introduction.html":{"url":"file/linux-introduction.html","title":"Linux 介绍","keywords":"","body":"1. Linux简介 严格来讲，Linux（内核）是计算机软件与硬件通信之间的平台，不是真正意义上的操作系统，而一些厂家将Linux内核和GNU软件（系统软件和工具）整合起来，并提供一些安装界面和系统设定与管理工具，就构成一些发行套件（系统），例如：Ubuntu、CentOS、Red Hat、Debian等。 Linux内核版本 Linux内核版本一般格式为：x.y.zz-www，例如：Kernel2.6.15 x.y：Linux内核主版本号，y若为奇数则表示是测试版 zz：次版本好 www：代表发行号 2. Linux体系结构 Linux体系结构如下： 几个重要概念： 内核：内核是操作系统的核心。内核直接与硬件交互，并处理大部分较低层的任务，如内存管理、进程调度、文件管理等。 Shell：Shell是一个处理用户请求的工具，它负责解释用户输入的命令，调用用户希望使用的程序。 命令和工具：日常工作中，你会用到很多系统命令和工具，如cp、mv、cat和grep等。 文件和目录：Linux系统中所有的数据都被存储到文件中，这些文件被分配到各个目录，构成文件系统。 3. 系统操作 3.1. 登录Linux 登录需要输入用户名和密码，用户名和密码是区分大小写。 login : amrood amrood's password: Last login: Sun Jun 14 09:32:32 2009 from 62.61.164.73 $ 3.2. 修改密码 输入password命令后，输入原密码和新密码，确认密码即可。 $ passwd Changing password for amrood (current) Linux password:****** New Linux password:******* Retype new Linux password:******* passwd: all authentication tokens updated successfully 3.3. 查看当前用户 1、查看自己的用户名 $ whoami amrood 2、查看当前在线用户 可以使用users 、who、w命令。 $ users amrood bablu qadir $ who amrood ttyp0 Oct 8 14:10 (limbo) bablu ttyp2 Oct 4 09:08 (calliope) qadir ttyp4 Oct 8 12:09 (dent) $ w 13:58:53 up 158 days, 22:07, 3 users, load average: 0.72, 0.99, 1.11 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT root pts/1 172.16.20.65 13:40 0.00s 0.22s 0.02s w root pts/2 172.16.20.65 Fri15 43:17m 1.04s 1.04s -bash 3.4. 关闭系统 关闭系统可以使用以下命令 命令 说明 halt 直接关闭系统 init 0 使用预先定义的脚本关闭系统，关闭前可以清理和更新有关信息 init 6 重新启动系统 poweroff 通过断电来关闭系统 reboot 重新启动系统 shutdown 安全关闭系统 一般只有root有关闭系统的权限，普通用户被赋予相应权限也可以关闭系统。 Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-09-23 17:44:10 "},"file/linux-file-permission.html":{"url":"file/linux-file-permission.html","title":"Linux 文件权限","keywords":"","body":"1. Linux文件管理 Linux中的所有数据都被保存在文件中，所有的文件被分配到不同的目录。目录是一种类似于树的结构，称为文件系统。 1.1. 文件类型 1、普通文件 普通文件是以字节为单位的数据流，包括文本文件、源码文件、可执行文件等。文本和二进制对Linux来说并无区别，对普通文件的解释由处理该文件的应用程序进行。 2、目录 目录可以包含普通文件和特殊文件，目录相当于Windows和Mac OS中的文件夹。 3、设备文件 Linux 与外部设备（例如光驱，打印机，终端，modern等）是通过一种被称为设备文件的文件来进行通信。Linux 输入输出到外部设备的方式和输入输出到一个文件的方式是相同的。Linux 和一个外部设备通讯之前，这个设备必须首先要有一个设备文件存在。 设备文件和普通文件不一样，设备文件中并不包含任何数据。 设备文件有两种类型：字符设备文件和块设备文件。 字符设备文件以字母\"c\"开头。字符设备文件向设备传送数据时，一次传送一个字符。典型的通过字符传送数据的设备有终端、打印机、绘图仪、modern等。字符设备文件有时也被称为\"raw\"设备文件。 块设备文件以字母\"b\"开头。块设备文件向设备传送数据时，先从内存中的buffer中读或写数据，而不是直接传送数据到物理磁盘。磁盘和CD-ROMS既可以使用字符设备文件也可以使用块设备文件。 1.2. 文件属性 可以使用ls -al来查看当前目录下的所有文件列表。 [root@www ~]# ls -al total 156 drwxr-x--- 4 root root 4096 Sep 8 14:06 . # 当前目录 drwxr-xr-x 23 root root 4096 Sep 8 14:21 .. # 父目录 -rw------- 1 root root 1474 Sep 4 18:27 anaconda-ks.cfg -rw------- 1 root root 199 Sep 8 17:14 .bash_history -rw-r--r-- 1 root root 24 Jan 6 2007 .bash_logout -rw-r--r-- 1 root root 191 Jan 6 2007 .bash_profile -rw-r--r-- 1 root root 176 Jan 6 2007 .bashrc -rw-r--r-- 1 root root 100 Jan 6 2007 .cshrc drwx------ 3 root root 4096 Sep 5 10:37 .gconf drwx------ 2 root root 4096 Sep 5 14:09 .gconfd -rw-r--r-- 1 root root 42304 Sep 4 18:26 install.log -rw-r--r-- 1 root root 5661 Sep 4 18:25 install.log.syslog [ 1 ] [ 2 ][ 3 ][ 4 ] [ 5 ] [ 6 ] [ 7 ] [ 权限 ][文件数][所有者] [用户组][文件容量][ 修改日期 ] [ 文件名 ] 每列含义说明： 第一列：文件类型。 第二列：表示文件个数。如果是文件，那么就是1；如果是目录，那么就是该目录中文件的数目。 第三列：文件的所有者，即文件的创建者。 第四列：文件所有者所在的用户组。在Linux中，每个用户都隶属于一个用户组。 第五列：文件大小（以字节计）。 第六列：文件被创建或上次被修改的时间。 第七列：文件名或目录名。 文件类型字符 前缀 描述 - 普通文件。如文本文件、二进制可执行文件、源代码等。 b 块设备文件。硬盘可以使用块设备文件。 c 字符设备文件。硬盘也可以使用字符设备文件。 d 目录文件。目录可以包含文件和其他目录。 l 符号链接（软链接）。可以链接任何普通文件，类似于 Windows 中的快捷方式。 p 具名管道。管道是进程间的一种通信机制。 s 用于进程间通信的套接字。 隐藏文件 隐藏文件的第一个字符为英文句号或点号(.)，Linux程序（包括Shell）通常使用隐藏文件来保存配置信息。可以通过ls -a来查看所有文件，即包含隐藏文件。 常见的隐藏文件： .profile：Bourne shell (sh) 初始化脚本 .kshrc：Korn shell (ksh) 初始化脚本 .cshrc：C shell (csh) 初始化脚本 .rhosts：Remote shell (rsh) 配置文件 1.3. 文件的操作 操作 命令 创建 touch filename 编辑 vi filename 查看 cat filename 复制 cp filename copyfile 重命名 mv filename newfile 删除 rm filename filename2 统计词数 wc filename 1.4. 标准的Linux流 一般情况下，每个Linux程序运行时都会创建三个文件流（三个文件）： 标准输入流(stdin)：stdin的文件描述符为0，Linux程序默认从stdin读取数据。 标准输出流(stdout)：stdout 的文件描述符为1，Linux程序默认向stdout输出数据。 标准错误流(stderr)：stderr的文件描述符为2，Linux程序会向stderr流中写入错误信息。 2. 文件权限和访问模式 2.1. 查看文件权限 Linux每个文件都有三类权限： 所有者权限(user)：文件所有者能够进行的操作 组权限(group)：文件所属用户组能够进行的操作 外部权限（other）：其他用户可以进行的操作。 通过ls -l的命令可以查看文件权限信息。 $ls -l /home/amrood -rwxr-xr-- 1 amrood users 1024 Nov 2 00:10 myfile drwxr-xr--- 1 amrood users 1024 Nov 2 00:10 mydir 第一列-rwxr-xr--包含了文件或目录的权限。 除了第一个字符-或d分别用来表示文件或目录外，其他的九个字符可以分为三组，分别对应所有者权限，用户组权限，其他用户权限，即-|user|group|other。 每组的权限又可分为三类： 读取（r），对应权限数字4 写入（w），对应权限数字2 执行（x），对应权限数字1 使用数字表示权限： 数字 说明 权限 0 没有任何权限 --- 1 执行权限 --x 2 写入权限 -w- 3 执行权限和写入权限：1 (执行) + 2 (写入) = 3 -wx 4 读取权限 r-- 5 读取和执行权限：4 (读取) + 1 (执行) = 5 r-x 6 读取和写入权限：4 (读取) + 2 (写入) = 6 rw- 7 所有权限: 4 (读取) + 2 (写入) + 1 (执行) = 7 rwx 2.2. 访问模式 2.2.1. 文件访问模式 基本的权限有读取(r)、写入(w)和执行(x)： 读取：用户能够读取文件信息，查看文件内容。 写入：用户可以编辑文件，可以向文件写入内容，也可以删除文件内容。 执行：用户可以将文件作为程序来运行。 2.2.2. 目录访问模式 目录的访问模式和文件类似，但是稍有不同： 读取：用户可以查看目录中的文件 写入：用户可以在当前目录中删除文件或创建文件 执行：执行权限赋予用户遍历目录的权利，例如执行 cd 和 ls 命令。 2.3. 权限的操作 2.3.1. chmod chmod (change mode) 命令来改变文件或目录的访问权限，权限可以使用符号或数字来表示。 1、通过符号方式 可以使用符号来改变文件或目录的权限，你可以增加(+)和删除(-)权限，也可以指定特定权限(=)。 指定权限范围 u (user)：所有者权限 g(group)：所属用户组权限 o(other)：其他用户权限 符号 说明 + 为文件或目录增加权限 - 删除文件或目录的权限 = 设置指定的权限 示例 # 查看权限 $ls -l testfile -rwxrwxr-- 1 amrood users 1024 Nov 2 00:10 testfile # 增加权限 $chmod o+wx testfile $ls -l testfile -rwxrwxrwx 1 amrood users 1024 Nov 2 00:10 testfile # 删除权限 $chmod u-x testfile $ls -l testfile -rw-rwxrwx 1 amrood users 1024 Nov 2 00:10 testfile # 指定权限 $chmod g=rx testfile $ls -l testfile -rw-r-xrwx 1 amrood users 1024 Nov 2 00:10 testfile # 同时使用多个符号 $chmod o+wx,u-x,g=rx testfile $ls -l testfile -rw-r-xrwx 1 amrood users 1024 Nov 2 00:10 testfile 2、通过数字权限方式 数字权限依照2.1的权限说明。 示例 $ls -l testfile -rwxrwxr-- 1 amrood users 1024 Nov 2 00:10 testfile $ chmod 755 testfile $ls -l testfile -rwxr-xr-x 1 amrood users 1024 Nov 2 00:10 testfile 2.3.2. chown chown 命令是\"change owner\"的缩写，用来改变文件的所有者。 # user可以是用户名或用户ID $ chown user filelist # 例如： $ chown amrood testfile 超级用户 root 可以不受限制的更改文件的所有者和用户组，但是普通用户只能更改所有者是自己的文件或目录。 2.3.3. chgrp chgrp 命令是\"change group\"的缩写，用来改变文件所在的群组。 # group可以是用户组名或用户组ID $ chgrp group filelist # 例如： $ chgrp special testfile 2.4. SUID和SGID位 在Linux中，一些程序需要特殊权限才能完成用户指定的操作。例如密码文件/etc/shadow。 Linux 通过给程序设置SUID(Set User ID)和SGID(Set Group ID)位来赋予普通用户特殊权限。当我们运行一个带有SUID位的程序时，就会继承该程序所有者的权限；如果程序不带SUID位，则会根据程序使用者的权限来运行。 例如： $ ls -l /usr/bin/passwd -r-sr-xr-x 1 root bin 19031 Feb 7 13:47 /usr/bin/passwd* 上面第一列第四个字符不是'x'或'-'，而是's'，说明 /usr/bin/passwd 文件设置了SUID位，这时普通用户会以root用户的权限来执行passwd程序。 小写字母's'说明文件所有者有执行权限(x)，大写字母'S'说明程序所有者没有执行权限(x)。 为一个目录设置SUID和SGID位可以使用下面的命令： $ chmod ug+s dirname $ ls -l drwsr-sr-x 2 root root 4096 Jun 19 06:45 dirname Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-09-23 17:44:10 "},"shell/shell-introduction.html":{"url":"shell/shell-introduction.html","title":"Shell简介","keywords":"","body":"1. Shell简介 shell是用户和Linux内核之间的一层代理，解释用户输入的命令，传递给内核。 shell是一种脚本语言（解释性语言）。 1.1. 编译型语言 任何代码运行最终都需要被翻译成二进制的形式在计算机中执行。C/C++、Go语言等语言，需要在程序运行之前将代码编译成二进制形式，生成可执行文件，用户执行的是可执行文件，看不到源码。 这个过程叫编译，这类语言叫编译型语言，完成编译过程的软件叫编译器。 1.2. 脚本型语言 有的语言（例如： Shell、JavaScript、Python、PHP等）需要一边执行一边翻译，不会产生任何可执行文件，用户需要拿到源码才能运行程序。程序运行后会即时翻译，翻译一部分执行一部分，并不用等所有代码翻译完。 这个过程叫解释，这类语言叫解释型语言或脚本语言，完成解释过程的软件叫解释器。 2. 常见的Shell类型 shell类型 说明 sh sh 是 UNIX 上的标准 shell，很多 UNIX 版本都配有 sh。 bash bash shell 是 Linux 的默认 shell，bash 兼容 sh，但并不完全一致。 csh 语法有点类似C语言。 ... 2.1. 查看shell $ cat /etc/shells /bin/sh /bin/bash /sbin/nologin /usr/bin/sh /usr/bin/bash /usr/sbin/nologin /bin/tcsh /bin/csh 查看默认shell $ echo $SHELL /bin/bash sh 一般被 bash 代替，/bin/sh往往是指向/bin/bash的符号链接。 $ ls -l /bin/sh lrwxrwxrwx. 1 root root 4 Mar 8 2018 /bin/sh -> bash 3. 执行shell #!/bin/bash echo \"Hello World !\" #!/bin/bash表示使用的解释器是什么。 3.1. 作为可执行程序运行 chmod +x ./test.sh #使脚本具有执行权限 ./test.sh #执行脚本 3.2. 作为解释器参数运行 # 使用 sh 解释器 sh test.sh # 使用 bash 解释器 bash test.sh Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-09-23 17:44:10 "},"tools/ansible-usage.html":{"url":"tools/ansible-usage.html","title":"Ansible的使用","keywords":"","body":"1. 安装 以centos为例。 yum install -y ansible 2. 配置 默认配置目录在/etc/ansible/，主要有以下两个配置： ansible.cfg：ansible的配置文件 hosts：配置ansible所连接的机器IP信息 2.1. ansible.cfg 2.2. hosts # This is the default ansible 'hosts' file. # # It should live in /etc/ansible/hosts # # - Comments begin with the '#' character # - Blank lines are ignored # - Groups of hosts are delimited by [header] elements # - You can enter hostnames or ip addresses # - A hostname/ip can be a member of multiple groups # Ex 1: Ungrouped hosts, specify before any group headers. # green.example.com # blue.example.com # 192.168.100.1 # 192.168.100.10 # Ex 2: A collection of hosts belonging to the 'webservers' group # [webservers] # alpha.example.org # beta.example.org # 192.168.1.100 # 192.168.1.110 # If you have multiple hosts following a pattern you can specify # them like this: # www[001:006].example.com # Ex 3: A collection of database servers in the 'dbservers' group # [dbservers] # # db01.intranet.mydomain.net # db02.intranet.mydomain.net # 10.25.1.56 # 10.25.1.57 # Here's another example of host ranges, this time there are no # leading 0s: # db-[99:101]-node.example.com [k8s] 192.168.201.52 192.168.201.53 192.168.201.54 192.168.201.55 192.168.201.56 192.168.201.57 3. ansible的命令 命令格式为：ansible [options] host-pattern：即hosts文件中配置的集群名称 options：命令操作符 例如：ansible k8s -a 'uname -r' [root@k8s-master ansible]# ansible k8s -a 'uname -r' 172.16.201.56 | SUCCESS | rc=0 >> 4.16.11-1.el7.elrepo.x86_64 172.16.201.55 | SUCCESS | rc=0 >> 4.16.11-1.el7.elrepo.x86_64 172.16.201.54 | SUCCESS | rc=0 >> 4.16.11-1.el7.elrepo.x86_64 172.16.201.53 | SUCCESS | rc=0 >> 4.16.11-1.el7.elrepo.x86_64 172.16.201.52 | SUCCESS | rc=0 >> 4.16.11-1.el7.elrepo.x86_64 172.16.201.57 | SUCCESS | rc=0 >> 4.16.11-1.el7.elrepo.x86_64 具体的命令信息： Usage: ansible [options] Define and run a single task 'playbook' against a set of hosts Options: -a MODULE_ARGS, --args=MODULE_ARGS module arguments --ask-vault-pass ask for vault password -B SECONDS, --background=SECONDS run asynchronously, failing after X seconds (default=N/A) -C, --check don't make any changes; instead, try to predict some of the changes that may occur -D, --diff when changing (small) files and templates, show the differences in those files; works great with --check -e EXTRA_VARS, --extra-vars=EXTRA_VARS set additional variables as key=value or YAML/JSON, if filename prepend with @ -f FORKS, --forks=FORKS specify number of parallel processes to use (default=5) -h, --help show this help message and exit -i INVENTORY, --inventory=INVENTORY, --inventory-file=INVENTORY specify inventory host path or comma separated host list. --inventory-file is deprecated -l SUBSET, --limit=SUBSET further limit selected hosts to an additional pattern --list-hosts outputs a list of matching hosts; does not execute anything else -m MODULE_NAME, --module-name=MODULE_NAME module name to execute (default=command) -M MODULE_PATH, --module-path=MODULE_PATH prepend colon-separated path(s) to module library (default=[u'/root/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']) -o, --one-line condense output --playbook-dir=BASEDIR Since this tool does not use playbooks, use this as a subsitute playbook directory.This sets the relative path for many features including roles/ group_vars/ etc. -P POLL_INTERVAL, --poll=POLL_INTERVAL set the poll interval if using -B (default=15) --syntax-check perform a syntax check on the playbook, but do not execute it -t TREE, --tree=TREE log output to this directory --vault-id=VAULT_IDS the vault identity to use --vault-password-file=VAULT_PASSWORD_FILES vault password file -v, --verbose verbose mode (-vvv for more, -vvvv to enable connection debugging) --version show program's version number and exit Connection Options: control as whom and how to connect to hosts -k, --ask-pass ask for connection password --private-key=PRIVATE_KEY_FILE, --key-file=PRIVATE_KEY_FILE use this file to authenticate the connection -u REMOTE_USER, --user=REMOTE_USER connect as this user (default=None) -c CONNECTION, --connection=CONNECTION connection type to use (default=smart) -T TIMEOUT, --timeout=TIMEOUT override the connection timeout in seconds (default=10) --ssh-common-args=SSH_COMMON_ARGS specify common arguments to pass to sftp/scp/ssh (e.g. ProxyCommand) --sftp-extra-args=SFTP_EXTRA_ARGS specify extra arguments to pass to sftp only (e.g. -f, -l) --scp-extra-args=SCP_EXTRA_ARGS specify extra arguments to pass to scp only (e.g. -l) --ssh-extra-args=SSH_EXTRA_ARGS specify extra arguments to pass to ssh only (e.g. -R) Privilege Escalation Options: control how and which user you become as on target hosts -s, --sudo run operations with sudo (nopasswd) (deprecated, use become) -U SUDO_USER, --sudo-user=SUDO_USER desired sudo user (default=root) (deprecated, use become) -S, --su run operations with su (deprecated, use become) -R SU_USER, --su-user=SU_USER run operations with su as this user (default=None) (deprecated, use become) -b, --become run operations with become (does not imply password prompting) --become-method=BECOME_METHOD privilege escalation method to use (default=sudo), valid choices: [ sudo | su | pbrun | pfexec | doas | dzdo | ksu | runas | pmrun | enable ] --become-user=BECOME_USER run operations as this user (default=root) --ask-sudo-pass ask for sudo password (deprecated, use become) --ask-su-pass ask for su password (deprecated, use become) -K, --ask-become-pass ask for privilege escalation password Some modules do not make sense in Ad-Hoc (include, meta, etc) 4. ansible-playbook Usage: ansible-playbook [options] playbook.yml [playbook2 ...] Runs Ansible playbooks, executing the defined tasks on the targeted hosts. Options: --ask-vault-pass ask for vault password -C, --check don't make any changes; instead, try to predict some of the changes that may occur -D, --diff when changing (small) files and templates, show the differences in those files; works great with --check -e EXTRA_VARS, --extra-vars=EXTRA_VARS set additional variables as key=value or YAML/JSON, if filename prepend with @ --flush-cache clear the fact cache for every host in inventory --force-handlers run handlers even if a task fails -f FORKS, --forks=FORKS specify number of parallel processes to use (default=5) -h, --help show this help message and exit -i INVENTORY, --inventory=INVENTORY, --inventory-file=INVENTORY specify inventory host path or comma separated host list. --inventory-file is deprecated -l SUBSET, --limit=SUBSET further limit selected hosts to an additional pattern --list-hosts outputs a list of matching hosts; does not execute anything else --list-tags list all available tags --list-tasks list all tasks that would be executed -M MODULE_PATH, --module-path=MODULE_PATH prepend colon-separated path(s) to module library (default=[u'/root/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']) --skip-tags=SKIP_TAGS only run plays and tasks whose tags do not match these values --start-at-task=START_AT_TASK start the playbook at the task matching this name --step one-step-at-a-time: confirm each task before running --syntax-check perform a syntax check on the playbook, but do not execute it -t TAGS, --tags=TAGS only run plays and tasks tagged with these values --vault-id=VAULT_IDS the vault identity to use --vault-password-file=VAULT_PASSWORD_FILES vault password file -v, --verbose verbose mode (-vvv for more, -vvvv to enable connection debugging) --version show program's version number and exit Connection Options: control as whom and how to connect to hosts -k, --ask-pass ask for connection password --private-key=PRIVATE_KEY_FILE, --key-file=PRIVATE_KEY_FILE use this file to authenticate the connection -u REMOTE_USER, --user=REMOTE_USER connect as this user (default=None) -c CONNECTION, --connection=CONNECTION connection type to use (default=smart) -T TIMEOUT, --timeout=TIMEOUT override the connection timeout in seconds (default=10) --ssh-common-args=SSH_COMMON_ARGS specify common arguments to pass to sftp/scp/ssh (e.g. ProxyCommand) --sftp-extra-args=SFTP_EXTRA_ARGS specify extra arguments to pass to sftp only (e.g. -f, -l) --scp-extra-args=SCP_EXTRA_ARGS specify extra arguments to pass to scp only (e.g. -l) --ssh-extra-args=SSH_EXTRA_ARGS specify extra arguments to pass to ssh only (e.g. -R) Privilege Escalation Options: control how and which user you become as on target hosts -s, --sudo run operations with sudo (nopasswd) (deprecated, use become) -U SUDO_USER, --sudo-user=SUDO_USER desired sudo user (default=root) (deprecated, use become) -S, --su run operations with su (deprecated, use become) -R SU_USER, --su-user=SU_USER run operations with su as this user (default=None) (deprecated, use become) -b, --become run operations with become (does not imply password prompting) --become-method=BECOME_METHOD privilege escalation method to use (default=sudo), valid choices: [ sudo | su | pbrun | pfexec | doas | dzdo | ksu | runas | pmrun | enable ] --become-user=BECOME_USER run operations as this user (default=root) --ask-sudo-pass ask for sudo password (deprecated, use become) --ask-su-pass ask for su password (deprecated, use become) -K, --ask-become-pass ask for privilege escalation password Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-09-23 17:44:10 "},"tools/supervisor-usage.html":{"url":"tools/supervisor-usage.html","title":"Supervisor的使用","keywords":"","body":"1. Supervisor简介 Supervisord 是用 Python 实现的一款的进程管理工具，supervisord 要求管理的程序是非 daemon 程序，supervisord 会帮你把它转成 daemon 程序，因此如果用 supervisord 来管理进程，进程需要以非daemon的方式启动。 例如：管理nginx 的话，必须在 nginx 的配置文件里添加一行设置 daemon off 让 nginx 以非 daemon 方式启动。 2. Supervisor安装 以centos系统为例，以下两种方式选择其一。 # yum install 的方式 yum install -y supervisor # easy_install的方式 yum install -y python-setuptools easy_install supervisor echo_supervisord_conf >/etc/supervisord.conf 3. Supervisor的配置 3.1. supervisord.conf的配置 如果使用yum install -y supervisor的命令安装，会生成默认配置/etc/supervisord.conf和目录/etc/supervisord.d，如果没有则自行创建。 在/etc/supervisord.d的目录下创建conf和log两个目录，conf用于存放管理进程的配置，log用于存放管理进程的日志。 cd /etc/supervisord.d mkdir conf log 修改/etc/supervisord.conf的[include]部分，即载入/etc/supervisord.d/conf目录下的所有配置。 vi /etc/supervisord.conf ... [include] files = supervisord.d/conf/*.conf ... 也可以修改supervisor应用日志的目录，默认日志路径为/var/log/supervisor/supervisord.log。 vi /etc/supervisord.conf ... [supervisord] logfile=/var/log/supervisor/supervisord.log ; (main log file;default $CWD/supervisord.log) logfile_maxbytes=50MB ; (max main logfile bytes b4 rotation;default 50MB) logfile_backups=10 ; (num of main logfile rotation backups;default 10) loglevel=info ; (log level;default info; others: debug,warn,trace) pidfile=/var/run/supervisord.pid ; (supervisord pidfile;default supervisord.pid) ... 3.2. 管理应用的配置 进入到/etc/supervisord.d/conf目录，创建管理应用的配置，可以创建多个应用配置。 例如，创建confd.conf配置。 [program:confd] directory = /usr/local/bin ; 程序的启动目录 command = /usr/local/bin/confd -config-file /etc/confd/confd.toml ; 启动命令，与命令行启动的命令是一样的 autostart = true ; 在 supervisord 启动的时候也自动启动 startsecs = 5 ; 启动 5 秒后没有异常退出，就当作已经正常启动了 autorestart = true ; 程序异常退出后自动重启 startretries = 3 ; 启动失败自动重试次数，默认是 3 user = root ; 用哪个用户启动 redirect_stderr = true ; 把 stderr 重定向到 stdout，默认 false stdout_logfile_maxbytes = 20MB ; stdout 日志文件大小，默认 50MB stdout_logfile_backups = 20 ; stdout 日志文件备份数 ; stdout 日志文件，需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录（supervisord 会自动创建日志文件） stdout_logfile = /etc/supervisord.d/log/confd.log ;日志统一放在log目录下 ; 可以通过 environment 来添加需要的环境变量，一种常见的用法是修改 PYTHONPATH ; environment=PYTHONPATH=$PYTHONPATH:/path/to/somewhere 4. Surpervisor的启动 # supervisord二进制启动 supervisord -c /etc/supervisord.conf # 检查进程 ps aux | grep supervisord 或者以systemd的方式管理 vi /etc/rc.d/init.d/supervisord #!/bin/sh # # /etc/rc.d/init.d/supervisord # # Supervisor is a client/server system that # allows its users to monitor and control a # number of processes on UNIX-like operating # systems. # # chkconfig: - 64 36 # description: Supervisor Server # processname: supervisord # Source init functions . /etc/rc.d/init.d/functions prog=\"supervisord\" prefix=\"/usr\" exec_prefix=\"${prefix}\" prog_bin=\"${exec_prefix}/bin/supervisord\" PIDFILE=\"/var/run/$prog.pid\" start() { echo -n $\"Starting $prog: \" daemon $prog_bin --pidfile $PIDFILE -c /etc/supervisord.conf [ -f $PIDFILE ] && success $\"$prog startup\" || failure $\"$prog startup\" echo } stop() { echo -n $\"Shutting down $prog: \" [ -f $PIDFILE ] && killproc $prog || success $\"$prog shutdown\" echo } case \"$1\" in start) start ;; stop) stop ;; status) status $prog ;; restart) stop start ;; *) echo \"Usage: $0 {start|stop|restart|status}\" ;; esac 设置开机启动及systemd方式启动。 sudo chmod +x /etc/rc.d/init.d/supervisord sudo chkconfig --add supervisord sudo chkconfig supervisord on sudo service supervisord start 5. supervisorctl&supervisord Supervisord 安装完成后有两个可用的命令行 supervisord 和 supervisorctl，命令使用解释如下： 5.1. supervisorctl supervisorctl stop programxxx，停止某一个进程(programxxx)，programxxx 为 [program:beepkg] 里配置的值，这个示例就是 beepkg。 supervisorctl start programxxx，启动某个进程。 supervisorctl restart programxxx，重启某个进程。 supervisorctl status，查看进程状态。 supervisorctl stop groupworker ，重启所有属于名为 groupworker 这个分组的进程(start,restart 同理)。 supervisorctl stop all，停止全部进程，注：start、restart、stop 都不会载入最新的配置文件。 supervisorctl reload，载入最新的配置文件，停止原有进程并按新的配置启动、管理所有进程。 supervisorctl update，根据最新的配置文件，启动新配置或有改动的进程，配置没有改动的进程不会受影响而重启。 更多参考： $ supervisorctl --help supervisorctl -- control applications run by supervisord from the cmd line. Usage: /usr/bin/supervisorctl [options] [action [arguments]] Options: -c/--configuration -- configuration file path (default /etc/supervisord.conf) -h/--help -- print usage message and exit -i/--interactive -- start an interactive shell after executing commands -s/--serverurl URL -- URL on which supervisord server is listening (default \"http://localhost:9001\"). -u/--username -- username to use for authentication with server -p/--password -- password to use for authentication with server -r/--history-file -- keep a readline history (if readline is available) action [arguments] -- see below Actions are commands like \"tail\" or \"stop\". If -i is specified or no action is specified on the command line, a \"shell\" interpreting actions typed interactively is started. Use the action \"help\" to find out about available actions. 例如： # supervisorctl status confd RUNNING pid 31256, uptime 0:11:24 twemproxy RUNNING pid 31255, uptime 0:11:24 5.2. supervisord supervisord，初始启动 Supervisord，启动、管理配置中设置的进程。 $ supervisord --help supervisord -- run a set of applications as daemons. Usage: /usr/bin/supervisord [options] Options: -c/--configuration FILENAME -- configuration file -n/--nodaemon -- run in the foreground (same as 'nodaemon true' in config file) -h/--help -- print this usage message and exit -v/--version -- print supervisord version number and exit -u/--user USER -- run supervisord as this user (or numeric uid) -m/--umask UMASK -- use this umask for daemon subprocess (default is 022) -d/--directory DIRECTORY -- directory to chdir to when daemonized -l/--logfile FILENAME -- use FILENAME as logfile path -y/--logfile_maxbytes BYTES -- use BYTES to limit the max size of logfile -z/--logfile_backups NUM -- number of backups to keep when max bytes reached -e/--loglevel LEVEL -- use LEVEL as log level (debug,info,warn,error,critical) -j/--pidfile FILENAME -- write a pid file for the daemon process to FILENAME -i/--identifier STR -- identifier used for this instance of supervisord -q/--childlogdir DIRECTORY -- the log directory for child process logs -k/--nocleanup -- prevent the process from performing cleanup (removal of old automatic child log files) at startup. -a/--minfds NUM -- the minimum number of file descriptors for start success -t/--strip_ansi -- strip ansi escape codes from process output --minprocs NUM -- the minimum number of processes available for start success --profile_options OPTIONS -- run supervisord under profiler and output results based on OPTIONS, which is a comma-sep'd list of 'cumulative', 'calls', and/or 'callers', e.g. 'cumulative,callers') 6. Supervisor控制台 在/etc/supervisord.conf中修改[inet_http_server]的参数，具体如下： [inet_http_server] ; inet (TCP) server disabled by default port=*:9001 ; ip_address:port specifier, *:port for all iface username=root ; default is no username (open server) password=xxxx ; default is no password (open server) 修改后重启supervisor进程，在浏览器访问 http://:9001。 具体如下： 图片 - supervisor 7. supervisor.conf详细配置 cat /etc/supervisord.conf ; Sample supervisor config file. [unix_http_server] file=/var/run/supervisor/supervisor.sock ; (the path to the socket file) ;chmod=0700 ; sockef file mode (default 0700) ;chown=nobody:nogroup ; socket file uid:gid owner ;username=user ; (default is no username (open server)) ;password=123 ; (default is no password (open server)) ;[inet_http_server] ; inet (TCP) server disabled by default ;port=127.0.0.1:9001 ; (ip_address:port specifier, *:port for all iface) ;username=user ; (default is no username (open server)) ;password=123 ; (default is no password (open server)) [supervisord] logfile=/var/log/supervisor/supervisord.log ; (main log file;default $CWD/supervisord.log) logfile_maxbytes=50MB ; (max main logfile bytes b4 rotation;default 50MB) logfile_backups=10 ; (num of main logfile rotation backups;default 10) loglevel=info ; (log level;default info; others: debug,warn,trace) pidfile=/var/run/supervisord.pid ; (supervisord pidfile;default supervisord.pid) nodaemon=false ; (start in foreground if true;default false) minfds=1024 ; (min. avail startup file descriptors;default 1024) minprocs=200 ; (min. avail process descriptors;default 200) ;umask=022 ; (process file creation umask;default 022) ;user=chrism ; (default is current user, required if root) ;identifier=supervisor ; (supervisord identifier, default is 'supervisor') ;directory=/tmp ; (default is not to cd during start) ;nocleanup=true ; (don't clean up tempfiles at start;default false) ;childlogdir=/tmp ; ('AUTO' child log dir, default $TEMP) ;environment=KEY=value ; (key value pairs to add to environment) ;strip_ansi=false ; (strip ansi escape codes in logs; def. false) ; the below section must remain in the config file for RPC ; (supervisorctl/web interface) to work, additional interfaces may be ; added by defining them in separate rpcinterface: sections [rpcinterface:supervisor] supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface [supervisorctl] serverurl=unix:///var/run/supervisor/supervisor.sock ; use a unix:// URL for a unix socket ;serverurl=http://127.0.0.1:9001 ; use an http:// url to specify an inet socket ;username=chris ; should be same as http_username if set ;password=123 ; should be same as http_password if set ;prompt=mysupervisor ; cmd line prompt (default \"supervisor\") ;history_file=~/.sc_history ; use readline history if available ; The below sample program section shows all possible program subsection values, ; create one or more 'real' program: sections to be able to control them under ; supervisor. ;[program:theprogramname] ;command=/bin/cat ; the program (relative uses PATH, can take args) ;process_name=%(program_name)s ; process_name expr (default %(program_name)s) ;numprocs=1 ; number of processes copies to start (def 1) ;directory=/tmp ; directory to cwd to before exec (def no cwd) ;umask=022 ; umask for process (default None) ;priority=999 ; the relative start priority (default 999) ;autostart=true ; start at supervisord start (default: true) ;autorestart=true ; retstart at unexpected quit (default: true) ;startsecs=10 ; number of secs prog must stay running (def. 1) ;startretries=3 ; max # of serial start failures (default 3) ;exitcodes=0,2 ; 'expected' exit codes for process (default 0,2) ;stopsignal=QUIT ; signal used to kill process (default TERM) ;stopwaitsecs=10 ; max num secs to wait b4 SIGKILL (default 10) ;user=chrism ; setuid to this UNIX account to run the program ;redirect_stderr=true ; redirect proc stderr to stdout (default false) ;stdout_logfile=/a/path ; stdout log path, NONE for none; default AUTO ;stdout_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB) ;stdout_logfile_backups=10 ; # of stdout logfile backups (default 10) ;stdout_capture_maxbytes=1MB ; number of bytes in 'capturemode' (default 0) ;stdout_events_enabled=false ; emit events on stdout writes (default false) ;stderr_logfile=/a/path ; stderr log path, NONE for none; default AUTO ;stderr_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB) ;stderr_logfile_backups=10 ; # of stderr logfile backups (default 10) ;stderr_capture_maxbytes=1MB ; number of bytes in 'capturemode' (default 0) ;stderr_events_enabled=false ; emit events on stderr writes (default false) ;environment=A=1,B=2 ; process environment additions (def no adds) ;serverurl=AUTO ; override serverurl computation (childutils) ; The below sample eventlistener section shows all possible ; eventlistener subsection values, create one or more 'real' ; eventlistener: sections to be able to handle event notifications ; sent by supervisor. ;[eventlistener:theeventlistenername] ;command=/bin/eventlistener ; the program (relative uses PATH, can take args) ;process_name=%(program_name)s ; process_name expr (default %(program_name)s) ;numprocs=1 ; number of processes copies to start (def 1) ;events=EVENT ; event notif. types to subscribe to (req'd) ;buffer_size=10 ; event buffer queue size (default 10) ;directory=/tmp ; directory to cwd to before exec (def no cwd) ;umask=022 ; umask for process (default None) ;priority=-1 ; the relative start priority (default -1) ;autostart=true ; start at supervisord start (default: true) ;autorestart=unexpected ; restart at unexpected quit (default: unexpected) ;startsecs=10 ; number of secs prog must stay running (def. 1) ;startretries=3 ; max # of serial start failures (default 3) ;exitcodes=0,2 ; 'expected' exit codes for process (default 0,2) ;stopsignal=QUIT ; signal used to kill process (default TERM) ;stopwaitsecs=10 ; max num secs to wait b4 SIGKILL (default 10) ;user=chrism ; setuid to this UNIX account to run the program ;redirect_stderr=true ; redirect proc stderr to stdout (default false) ;stdout_logfile=/a/path ; stdout log path, NONE for none; default AUTO ;stdout_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB) ;stdout_logfile_backups=10 ; # of stdout logfile backups (default 10) ;stdout_events_enabled=false ; emit events on stdout writes (default false) ;stderr_logfile=/a/path ; stderr log path, NONE for none; default AUTO ;stderr_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB) ;stderr_logfile_backups ; # of stderr logfile backups (default 10) ;stderr_events_enabled=false ; emit events on stderr writes (default false) ;environment=A=1,B=2 ; process environment additions ;serverurl=AUTO ; override serverurl computation (childutils) ; The below sample group section shows all possible group values, ; create one or more 'real' group: sections to create \"heterogeneous\" ; process groups. ;[group:thegroupname] ;programs=progname1,progname2 ; each refers to 'x' in [program:x] definitions ;priority=999 ; the relative start priority (default 999) ; The [include] section can just contain the \"files\" setting. This ; setting can list multiple files (separated by whitespace or ; newlines). It can also contain wildcards. The filenames are ; interpreted as relative to this file. Included files *cannot* ; include files themselves. [include] files = supervisord.d/conf/*.conf 参考： http://supervisord.org/ Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-09-23 17:44:10 "},"tools/confd-usage.html":{"url":"tools/confd-usage.html","title":"Confd的使用","keywords":"","body":"1. confd的部署 以下Linux系统为例。 下载confd的二进制文件，下载地址为：https://github.com/kelseyhightower/confd/releases。例如： # Download the binary wget https://github.com/kelseyhightower/confd/releases/download/v0.16.0/confd-0.16.0-linux-amd64 # 重命名二进制文件，并移动到PATH的目录下 mv confd-0.16.0-linux-amd64 /usr/local/bin/confd chmod +x /usr/local/bin/confd # 验证是否安装成功 confd --help 2. confd的配置 Confd通过读取后端存储的配置信息来动态更新对应的配置文件，对应的后端存储可以是etcd，redis等，其中etcd的v3版本对应的存储后端为etcdv3。 2.1. 创建confdir confdir底下包含两个目录: conf.d:confd的配置文件，主要包含配置的生成逻辑，例如模板源，后端存储对应的keys，命令执行等。 templates:配置模板Template，即基于不同组件的配置，修改为符合 Golang text templates的模板文件。 sudo mkdir -p /etc/confd/{conf.d,templates} 2.2. Template Resources 模板源配置文件是TOML格式的文件，主要包含配置的生成逻辑，例如模板源，后端存储对应的keys，命令执行等。默认目录在/etc/confd/conf.d。 参数说明： 必要参数 dest (string) - The target file. keys (array of strings) - An array of keys. src (string) - The relative path of a configuration template. 可选参数 gid (int) - The gid that should own the file. Defaults to the effective gid. mode (string) - The permission mode of the file. uid (int) - The uid that should own the file. Defaults to the effective uid. reload_cmd (string) - The command to reload config. check_cmd (string) - The command to check config. Use `` to reference the rendered source template. prefix (string) - The string to prefix to keys. 例子 例如：/etc/confd/conf.d/myapp-nginx.toml [template] prefix = \"/myapp\" src = \"nginx.tmpl\" dest = \"/tmp/myapp.conf\" owner = \"nginx\" mode = \"0644\" keys = [ \"/services/web\" ] check_cmd = \"/usr/sbin/nginx -t -c {{.src}}\" reload_cmd = \"/usr/sbin/service nginx reload\" 2.3. Template Template定义了单一应用配置的模板，默认存储在/etc/confd/templates目录下，模板文件符合Go的text/template格式。 模板文件常用函数有base，get，gets，lsdir，json等。具体可参考https://github.com/kelseyhightower/confd/blob/master/docs/templates.md。 例子： /etc/confd/templates/nginx.tmpl {{range $dir := lsdir \"/services/web\"}} upstream {{base $dir}} { {{$custdir := printf \"/services/web/%s/*\" $dir}}{{range gets $custdir}} server {{$data := json .Value}}{{$data.IP}}:80; {{end}} } server { server_name {{base $dir}}.example.com; location / { proxy_pass {{base $dir}}; } } {{end}} 3. 创建后端存储的配置数据 以etcdv3存储为例，在etcd中创建以下数据。 etcdctl --endpoints=$endpoints put /services/web/cust1/2 '{\"IP\": \"10.0.0.2\"}' etcdctl --endpoints=$endpoints put /services/web/cust2/2 '{\"IP\": \"10.0.0.4\"}' etcdctl --endpoints=$endpoints put /services/web/cust2/1 '{\"IP\": \"10.0.0.3\"}' etcdctl --endpoints=$endpoints put /services/web/cust1/1 '{\"IP\": \"10.0.0.1\"}' 4. 启动confd的服务 confd支持以daemon或者onetime两种模式运行，当以daemon模式运行时，confd会监听后端存储的配置变化，并根据配置模板动态生成目标配置文件。 如果以daemon模式运行，则执行以下命令： confd -watch -backend etcdv3 -node http://172.16.5.4:12379 & 以下以onetime模式运行为例。其中对应的后端存储类型是etcdv3。 # 执行命令 confd -onetime -backend etcdv3 -node http://172.16.5.4:12379 # output 2018-05-11T18:04:59+08:00 k8s-dbg-master-1 confd[35808]: INFO Backend set to etcdv3 2018-05-11T18:04:59+08:00 k8s-dbg-master-1 confd[35808]: INFO Starting confd 2018-05-11T18:04:59+08:00 k8s-dbg-master-1 confd[35808]: INFO Backend source(s) set to http://172.16.5.4:12379 2018-05-11T18:04:59+08:00 k8s-dbg-master-1 confd[35808]: INFO /root/myapp/twemproxy/conf/twemproxy.conf has md5sum 6f0f43abede612c75cb840a4840fbea3 should be 32f48664266e3fd6b56ee73a314ee272 2018-05-11T18:04:59+08:00 k8s-dbg-master-1 confd[35808]: INFO Target config /root/myapp/twemproxy/conf/twemproxy.conf out of sync 2018-05-11T18:04:59+08:00 k8s-dbg-master-1 confd[35808]: INFO Target config /root/myapp/twemproxy/conf/twemproxy.conf has been updated 5. 查看生成的配置文件 在/etc/confd/conf.d/myapp-nginx.toml中定义的配置文件的生成路径为/tmp/myapp.conf。 [root@k8s-dbg-master-1 dest]# cat myapp.conf upstream cust1 { server 10.0.0.1:80; server 10.0.0.2:80; } server { server_name cust1.example.com; location / { proxy_pass cust1; } } upstream cust2 { server 10.0.0.3:80; server 10.0.0.4:80; } server { server_name cust2.example.com; location / { proxy_pass cust2; } } 6. confd动态更新twemproxy 6.1. twemproxy.toml confd的模板源文件配置：/etc/confd/conf.d/twemproxy.toml [template] src = \"twemproxy.tmpl\" dest = \"/root/myapp/twemproxy/conf/twemproxy.conf\" keys = [ \"/twemproxy/pool\" ] check_cmd = \"/usr/local/bin/nutcracker -t -c /root/myapp/twemproxy/conf/twemproxy.conf\" reload_cmd = \"bash /root/myapp/twemproxy/reload.sh\" 6.2. twemproxy.tmpl 模板文件：/etc/confd/templates/twemproxy.tmpl global: worker_processes: 4 # 并发进程数, 如果为0, 这 fallback 回原来的单进程模型(不支持 config reload!) user: nobody # worker 进程的用户, 默认 nobody. 只要主进程是 root 用户启动才生效. group: nobody # worker 进程的用户组 worker_shutdown_timeout: 30 # 单位为秒. 用于 reload 过程中在改时间段之后强制退出旧的 worker 进程. pools: {{range gets \"/twemproxy/pool/*\"}} {{base .Key}}: {{$pool := json .Value}} listen: {{$pool.ListenAddr.IP}}:{{$pool.ListenAddr.Port}} hash: fnv1a_64 # 选择实例的 hash 规则 distribution: ketama auto_eject_hosts: true # server 有问题是否剔除 redis: true # 是否为 Redis 协议 {{if $pool.Password}}redis_auth: {{$pool.Password}}{{end}} server_retry_timeout: 5000 # 被剔除多长时间后会重试 server_connections: 25 # NOTE: server 连接池的大小, 默认为 1, 建议调整 server_failure_limit: 5 # 失败多少次后暂时剔除 timeout: 1000 # Server 超时时间, 1 sec backlog: 1024 # 连接队列大小 preconnect: true # 预连接大小 servers:{{range $server := $pool.Servers}} - {{$server.IP}}:{{$server.Port}}:1 {{if $server.Master}}master{{end}} {{end}} {{end}} 6.3. etcd中的配置格式 etcd中的配置通过一个map来定义为完整的配置内容。其中key是twemproxy中pool的名称，value是pool的所有内容。 配置对应go结构体如下： type Pool struct{ ListenAddr ListenAddr `json:\"ListenAddr,omitempty\"` Servers []Server `json:\"Servers,omitempty\"` Password string `json:\"Password,omitempty\"` } type ListenAddr struct { IP string `json:\"IP,omitempty\"` Port string `json:\"Port,omitempty\"` } type Server struct { IP string `json:\"IP,omitempty\"` Port string `json:\"Port,omitempty\"` Master bool `json:\"Master,omitempty\"` } 配置对应JSON格式如下： { \"ListenAddr\": { \"IP\": \"192.168.5.7\", \"Port\": \"22225\" }, \"Servers\": [ { \"IP\": \"10.233.116.168\", \"Port\": \"6379\", \"Master\": true }, { \"IP\": \"10.233.110.207\", \"Port\": \"6379\", \"Master\": false } ], \"Password\": \"987654\" } 6.4. 生成twemproxy配置文件 global: worker_processes: 4 # 并发进程数, 如果为0, 这 fallback 回原来的单进程模型(不支持 config reload!) user: nobody # worker 进程的用户, 默认 nobody. 只要主进程是 root 用户启动才生效. group: nobody # worker 进程的用户组 worker_shutdown_timeout: 30 # 单位为秒. 用于 reload 过程中在改时间段之后强制退出旧的 worker 进程. pools: redis1: listen: 192.168.5.7:22223 hash: fnv1a_64 # 选择实例的 hash 规则 distribution: ketama auto_eject_hosts: true # server 有问题是否剔除 redis: true # 是否为 Redis 协议 redis_auth: 987654 server_retry_timeout: 5000 # 被剔除多长时间后会重试 server_connections: 25 # NOTE: server 连接池的大小, 默认为 1, 建议调整 server_failure_limit: 5 # 失败多少次后暂时剔除 timeout: 1000 # Server 超时时间, 1 sec backlog: 1024 # 连接队列大小 preconnect: true # 预连接大小 servers: - 10.233.116.169:6379:1 redis2: listen: 192.168.5.7:22224 hash: fnv1a_64 # 选择实例的 hash 规则 distribution: ketama auto_eject_hosts: true # server 有问题是否剔除 redis: true # 是否为 Redis 协议 redis_auth: 987654 server_retry_timeout: 5000 # 被剔除多长时间后会重试 server_connections: 25 # NOTE: server 连接池的大小, 默认为 1, 建议调整 server_failure_limit: 5 # 失败多少次后暂时剔除 timeout: 1000 # Server 超时时间, 1 sec backlog: 1024 # 连接队列大小 preconnect: true # 预连接大小 servers: - 10.233.110.223:6379:1 master - 10.233.111.21:6379:1 参考文章： https://github.com/kelseyhightower/confd/blob/master/docs/installation.md https://github.com/kelseyhightower/confd/blob/master/docs/quick-start-guide.md https://github.com/kelseyhightower/confd/blob/master/docs/template-resources.md https://github.com/kelseyhightower/confd/blob/master/docs/templates.md Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-09-23 17:44:10 "},"tools/nfs-usage.html":{"url":"tools/nfs-usage.html","title":"NFS的使用","keywords":"","body":"1. NFS简介 NFS，是Network File System的简写，即网络文件系统。网络文件系统是FreeBSD支持的文件系统中的一种，也被称为NFS. NFS允许一个系统在网络上与他人共享目录和文件。 通过使用NFS，用户和程序可以像访问本地文件一样访问远端系统上的文件。 2. NFS的安装与配置 2.1 服务端 NFS需要安装nfs-utils、rpcbind两个包。 #可以先检查下本地是否已经安装，如果安装则无需重复安装包 [root@k8s-dbg-master-1 build]# rpm -qa|grep rpcbind rpcbind-0.2.0-42.el7.x86_64 [root@k8s-dbg-master-1 build]# rpm -qa|grep nfs libnfsidmap-0.25-17.el7.x86_64 nfs-utils-1.3.0-0.48.el7_4.x86_64 2.1.1. 安装nfs-utils、rpcbind两个包 #centos系统 yum -y install nfs-utils rpcbind #Ubuntu系统 #服务端 apt-get install nfs-kernel-server #客户端 apt-get install nfs-common 2.1.2. 创建共享目录 服务端共享目录：/data/nfs-storage/ mkdir /data/nfs-storage/ 2.1.3. NFS共享目录文件配置 vi /etc/exports #添加以下信息 /data/nfs-storage *(rw,insecure,sync,no_subtree_check,no_root_squash) 以上配置分为三个部分： 第一部分就是本地要共享出去的目录。 第二部分为允许访问的主机（可以是一个IP也可以是一个IP段），*代表允许所有的网段访问。 第三部分小括号里面的，为一些权限选项。 权限说明 rw ：读写； ro ：只读； sync ：同步模式，内存中数据时时写入磁盘； async ：不同步，把内存中数据定期写入磁盘中； secure ：nfs通过1024以下的安全TCP/IP端口发送 insecure ：nfs通过1024以上的端口发送 no_root_squash ：加上这个选项后，root用户就会对共享的目录拥有至高的权限控制，就像是对本机的目录操作一样。不安全，不建议使用； root_squash ：和上面的选项对应，root用户对共享目录的权限不高，只有普通用户的权限，即限制了root； subtree_check ：如果共享/usr/bin之类的子目录时，强制nfs检查父目录的权限（默认） no_subtree_check ：和上面相对，不检查父目录权限 all_squash ：不管使用NFS的用户是谁，他的身份都会被限定成为一个指定的普通用户身份； anonuid/anongid ：要和root_squash 以及 all_squash一同使用，用于指定使用NFS的用户限定后的uid和gid，前提是本机的/etc/passwd中存在这个uid和gid。 2.1.4. 启动NFS服务 #先启动rpcbind service rpcbind start #后启动nfs service nfs start #可以设置开机启动 chkconfig rpcbind on chkconfig nfs on 2.1.5. 服务端验证 通过showmount -e命令如果正常显示共享目录，表示安装正常。 [root@k8s-dbg-master-1 build]# showmount -e Export list for k8s-dbg-master-1: /data/nfs-storage * 2.2 客户端 2.2.1. 安装nfs-utils的包 yum install nfs-utils.x86_64 -y 2.2.2. 创建挂载点 客户端挂载目录：/mnt/store mkdir /mnt/store 2.2.3. 查看NFS服务器的共享 root@k8s-dbg-node-5:~# showmount -e 172.16.5.4 Export list for 172.16.5.4: /data/nfs-storage * 2.2.4. 挂载 mount -t nfs : #例如： mount -t nfs 172.16.5.4:/data/nfs-storage /mnt/store 2.2.5. 验证挂载信息 使用mount命令 root@k8s-dbg-node-5:~# mount |grep /mnt/store 172.16.5.4:/data/nfs-storage/k8s-storage/ssd on /mnt/store type nfs4 (rw,relatime,vers=4.0,rsize=1048576,wsize=1048576,namlen=255,hard,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=172.16.200.24,local_lock=none,addr=172.16.5.4) 使用df -h命令 root@k8s-dbg-node-5:~# df -h|grep nfs 172.16.5.4:/data/nfs-storage 40G 25G 13G 67% /mnt/store 创建文件测试 #进入客户端的挂载目录，创建文件 cd /mnt/store touch test.txt #进入服务端的共享目录，查看客户端创建的文件是否同步 cd /data/nfs-storage ls Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-09-23 17:44:10 "},"git/git.html":{"url":"git/git.html","title":"Git 介绍","keywords":"","body":"1. Git是什么 1.1. 概述 Git是分布式版本控制系统，与SVN类似的集中化版本控制系统相比，集中化版本控制系统如果中央服务器宕机则会影响数据和协同开发。 Git是分布式的版本控制系统，客户端不只是提取最新版本的快照，而且将整个代码仓库镜像复制下来。如果任何协同工作用的服务器发生故障了，也可以用任何一个代码仓库来恢复。而且在协作服务器宕机期间，你也可以提交代码到本地仓库，当协作服务器正常工作后，你再将本地仓库同步到远程仓库。 1.2. 特性 能够对文件版本控制和多人协作开发 拥有强大的分支特性，所以能够灵活地以不同的工作流协同开发 分布式版本控制系统，即使协作服务器宕机，也能继续提交代码或文件到本地仓库，当协作服务器恢复正常工作时，再将本地仓库同步到远程仓库。 当团队中某个成员完成某个功能时，通过pull request操作来通知其他团队成员，其他团队成员能够review code后再合并代码。 2. 为什么要用Git 能够对文件版本控制和多人协作开发 拥有强大的分支特性，所以能够灵活地以不同的工作流协同开发 分布式版本控制系统，即使协作服务器宕机，也能继续提交代码或文件到本地仓库，当协作服务器恢复正常工作时，再将本地仓库同步到远程仓库。 当团队中某个成员完成某个功能时，通过pull request操作来通知其他团队成员，其他团队成员能够review code后再合并代码。 3. Git 命令思维导图 图片 - git-map Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-09-23 20:27:01 "},"git/git-common-cmd.html":{"url":"git/git-common-cmd.html","title":"Git 常用命令","keywords":"","body":"1. Git常用命令 分类 子类 git command zsh alias 分支 查看当前分支 git branch gb 创建新分支,仍停留在当前分支 git branch 创建并切换到新分支 git checkout -b gcb 切换分支 git checkout 合并分支 git checkout #切换到要合并的分支git merge –no-ff #合并指定分支到当前分支 提交 查看状态 git status gst 查看修改部分 git diff --color gd 添加文件到暂存区 git add --all 提交本地仓库 git commit -m \"\" 推送到指定分支 git push -u origin 查看提交日志 git log - 2. git rebase 如果信息修改无法生效，设置永久环境变量：export EDITOR=vim 帮助信息： # Rebase 67da308..6ef692b onto 67da308 (1 command) # # Commands: # p, pick = use commit # r, reword = use commit, but edit the commit message # e, edit = use commit, but stop for amending # s, squash = use commit, but meld into previous commit # f, fixup = like \"squash\", but discard this commit's log message # x, exec = run command (the rest of the line) using shell # d, drop = remove commit # # These lines can be re-ordered; they are executed from top to bottom. # # If you remove a line here THAT COMMIT WILL BE LOST. # # However, if you remove everything, the rebase will be aborted. # # Note that empty commits are commented out 2.1. 合并多余提交记录 #以交互的方式进行rebase git rebase -i master #合并多余提交记录：s, squash = use commit, but meld into previous commit pick 6ef692b FIX: Fix parsing docker image version error s 3df667y FIX: the second push s 3fds95t FIX: the third push 保存退出 # 进入修改交互界面 删除需要删除的提交记录，保存退出 #查看提交记录是否已被修改 git log #最后强制提交到分支 git commit --force -u origin fix/add-unit-test-for-global-role-revoking 2.2. 修改提交记录 #以交互的方式进行rebase git rebase -i master #修改提交记录：e, edit = use commit, but stop for amending e 6ef692b FIX: Fix parsing docker image version error e 5ty697u FIX: Fix parsing docker image version error #保存退出 git commit --amend #修改提交记录内容，保存退出 git rebase --continue git commit --amend #修改下一条提交记录，保存退出 git rebase --continue git status # 查看状态提示 #最后强制提交到分支 git commit --force -u origin fix/add-unit-test-for-global-role-revoking #查看提交记录是否已被修改 git log 3. git设置忽略特殊文件 3.1. 忽略文件的原则 忽略操作系统自动生成的文件，比如缩略图等； 忽略编译生成的中间文件、可执行文件等，也就是如果一个文件是通过另一个文件自动生成的，那自动生成的文件就没必要放进版本库，比如Java编译产生的.class文件； 忽略你自己的带有敏感信息的配置文件，比如存放口令的配置文件。 3.2. 设置的方法 在项目的workdir 下编辑 .gitignore 文件，文件的路径填写为workdir的相对路径。 .idea/ #IDE的配置文件 _build/ server/server #二进制文件 3.3. gitignore 不生效解决方法 原因是.gitignore只能忽略那些原来没有被track的文件，如果某些文件已经被纳入了版本管理中，则修改.gitignore是无效的。那么解决方法就是先把本地缓存删除（改变成未track状态），然后再提交： git rm -r --cached . git add . git commit -m 'update .gitignore' 4. Git分支重命名 假设分支名称为oldName 想要修改为 newName 1. 本地分支重命名(还没有推送到远程) git branch -m oldName newName 2. 远程分支重命名 (已经推送远程-假设本地分支和远程对应分支名称相同) a. 重命名远程分支对应的本地分支 git branch -m oldName newName b. 删除远程分支 git push --delete origin oldName c. 上传新命名的本地分支 git push origin newName d.把修改后的本地分支与远程分支关联 git branch --set-upstream-to origin/newName 5. 代码冲突 git checkout master git pull git checkout git rebase -i master fix conflict git rebase --continue git push --force -u origin 6. 修改历史提交的用户信息 1、克隆并进入你的仓库 git clone --bare https://github.com/user/repo.git cd repo.git 2、创建以下脚本，例如命名为rename.sh #!/bin/sh git filter-branch --env-filter ' OLD_EMAIL=\"your-old-email@example.com\" #修改参数为你的旧提交邮箱 CORRECT_NAME=\"Your Correct Name\" #修改参数为你新的用户名 CORRECT_EMAIL=\"your-correct-email@example.com\" #修改参数为你新的邮箱名 if [ \"$GIT_COMMITTER_EMAIL\" = \"$OLD_EMAIL\" ] then export GIT_COMMITTER_NAME=\"$CORRECT_NAME\" export GIT_COMMITTER_EMAIL=\"$CORRECT_EMAIL\" fi if [ \"$GIT_AUTHOR_EMAIL\" = \"$OLD_EMAIL\" ] then export GIT_AUTHOR_NAME=\"$CORRECT_NAME\" export GIT_AUTHOR_EMAIL=\"$CORRECT_EMAIL\" fi ' --tag-name-filter cat -- --branches --tags 3、执行脚本 chmod +x rename.sh sh rename.sh 4、查看新 Git 历史有没有错误。 #可以看到提交记录的用户信息已经修改为新的用户信息 git log 5、确认提交内容，重新提交（可以先把rename.sh移除掉） git push --force --tags origin 'refs/heads/*' 7. 撤销已经push的提交 # 本地仓库回退到某一版本 git reset -hard # 强制 PUSH，此时远程分支已经恢复成指定的 commit 了 git push origin master --force Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-09-23 21:10:18 "},"git/git-commands.html":{"url":"git/git-commands.html","title":"Git 命令分类","keywords":"","body":"Git 命令详解 1. 示意图 图片 - 这里写图片描述 Workspace：工作区 Index / Stage：暂存区 Repository：仓库区（或本地仓库） Remote：远程仓库 2. Git 命令分类 2.1. 新建代码库 # 在当前目录新建一个Git代码库 $ git init # 新建一个目录，将其初始化为Git代码库 $ git init [project-name] # 下载一个项目和它的整个代码历史 $ git clone [url] 2.2. 配置 Git的设置文件为.gitconfig，它可以在用户主目录下（全局配置），也可以在项目目录下（项目配置）。 # 显示当前的Git配置 $ git config --list # 编辑Git配置文件 $ git config -e [--global] # 设置提交代码时的用户信息 $ git config [--global] user.name \"[name]\" $ git config [--global] user.email \"[email address]\" 2.3. 增加/删除文件 # 添加指定文件到暂存区 $ git add [file1] [file2] ... # 添加指定目录到暂存区，包括子目录 $ git add [dir] # 添加当前目录的所有文件到暂存区 $ git add . # 添加每个变化前，都会要求确认 # 对于同一个文件的多处变化，可以实现分次提交 $ git add -p # 删除工作区文件，并且将这次删除放入暂存区 $ git rm [file1] [file2] ... # 停止追踪指定文件，但该文件会保留在工作区 $ git rm --cached [file] # 改名文件，并且将这个改名放入暂存区 $ git mv [file-original] [file-renamed] 2.4. 代码提交 # 提交暂存区到仓库区 $ git commit -m [message] # 提交暂存区的指定文件到仓库区 $ git commit [file1] [file2] ... -m [message] # 提交工作区自上次commit之后的变化，直接到仓库区 $ git commit -a # 提交时显示所有diff信息 $ git commit -v # 使用一次新的commit，替代上一次提交 # 如果代码没有任何新变化，则用来改写上一次commit的提交信息 $ git commit --amend -m [message] # 重做上一次commit，并包括指定文件的新变化 $ git commit --amend [file1] [file2] ... 2.5. 分支 # 列出所有本地分支 $ git branch # 列出所有远程分支 $ git branch -r # 列出所有本地分支和远程分支 $ git branch -a # 新建一个分支，但依然停留在当前分支 $ git branch [branch-name] # 新建一个分支，并切换到该分支 $ git checkout -b [branch] # 新建一个分支，指向指定commit $ git branch [branch] [commit] # 新建一个分支，与指定的远程分支建立追踪关系 $ git branch --track [branch] [remote-branch] # 切换到指定分支，并更新工作区 $ git checkout [branch-name] # 切换到上一个分支 $ git checkout - # 建立追踪关系，在现有分支与指定的远程分支之间 $ git branch --set-upstream [branch] [remote-branch] # 合并指定分支到当前分支 $ git merge [branch] # 选择一个commit，合并进当前分支 $ git cherry-pick [commit] # 删除分支 $ git branch -d [branch-name] # 删除远程分支 $ git push origin --delete [branch-name] $ git branch -dr [remote/branch] 2.6. 标签 # 列出所有tag $ git tag # 新建一个tag在当前commit $ git tag [tag] # 新建一个tag在指定commit $ git tag [tag] [commit] # 删除本地tag $ git tag -d [tag] # 删除远程tag $ git push origin :refs/tags/[tagName] # 查看tag信息 $ git show [tag] # 提交指定tag $ git push [remote] [tag] # 提交所有tag $ git push [remote] --tags # 新建一个分支，指向某个tag $ git checkout -b [branch] [tag] 2.7. 查看信息 # 显示有变更的文件 $ git status # 显示当前分支的版本历史 $ git log # 显示commit历史，以及每次commit发生变更的文件 $ git log --stat # 搜索提交历史，根据关键词 $ git log -S [keyword] # 显示某个commit之后的所有变动，每个commit占据一行 $ git log [tag] HEAD --pretty=format:%s # 显示某个commit之后的所有变动，其\"提交说明\"必须符合搜索条件 $ git log [tag] HEAD --grep feature # 显示某个文件的版本历史，包括文件改名 $ git log --follow [file] $ git whatchanged [file] # 显示指定文件相关的每一次diff $ git log -p [file] # 显示过去5次提交 $ git log -5 --pretty --oneline # 显示所有提交过的用户，按提交次数排序 $ git shortlog -sn # 显示指定文件是什么人在什么时间修改过 $ git blame [file] # 显示暂存区和工作区的差异 $ git diff # 显示暂存区和上一个commit的差异 $ git diff --cached [file] # 显示工作区与当前分支最新commit之间的差异 $ git diff HEAD # 显示两次提交之间的差异 $ git diff [first-branch]...[second-branch] # 显示今天你写了多少行代码 $ git diff --shortstat \"@{0 day ago}\" # 显示某次提交的元数据和内容变化 $ git show [commit] # 显示某次提交发生变化的文件 $ git show --name-only [commit] # 显示某次提交时，某个文件的内容 $ git show [commit]:[filename] # 显示当前分支的最近几次提交 $ git reflog 2.8. 远程同步 # 下载远程仓库的所有变动 $ git fetch [remote] # 显示所有远程仓库 $ git remote -v # 显示某个远程仓库的信息 $ git remote show [remote] # 增加一个新的远程仓库，并命名 $ git remote add [shortname] [url] # 取回远程仓库的变化，并与本地分支合并 $ git pull [remote] [branch] # 上传本地指定分支到远程仓库 $ git push [remote] [branch] # 强行推送当前分支到远程仓库，即使有冲突 $ git push [remote] --force # 推送所有分支到远程仓库 $ git push [remote] --all 2.9. 撤销 # 恢复暂存区的指定文件到工作区 $ git checkout [file] # 恢复某个commit的指定文件到暂存区和工作区 $ git checkout [commit] [file] # 恢复暂存区的所有文件到工作区 $ git checkout . # 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变 $ git reset [file] # 重置暂存区与工作区，与上一次commit保持一致 $ git reset --hard # 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变 $ git reset [commit] # 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致 $ git reset --hard [commit] # 重置当前HEAD为指定commit，但保持暂存区和工作区不变 $ git reset --keep [commit] # 新建一个commit，用来撤销指定commit # 后者的所有变化都将被前者抵消，并且应用到当前分支 $ git revert [commit] # 暂时将未提交的变化移除，稍后再移入 $ git stash $ git stash pop 2.10. 其他 # 生成一个可供发布的压缩包 $ git archive # 设置换行符为LF git config --global core.autocrlf false #拒绝提交包含混合换行符的文件 git config --global core.safecrlf true 参考文章： http://www.ruanyifeng.com/blog/2015/12/git-cheat-sheet.html Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-09-23 20:39:00 "},"nginx/install-nginx.html":{"url":"nginx/install-nginx.html","title":"Nginx安装与配置","keywords":"","body":"1. 部署 1.1. 使用安装包的方式 rpm -ivh nginx-xxx.rpm 1.2. 使用源代码安装 1.2.1. 下载源码包 wget http://blob.wae.haplat.net/nginx/nginx-1.9.13.tar.gz 1.2.2. 创建临时目录并解压源码包 mkdir $HOME/build cd $HOME/build && tar zxvf nginx-.tar.gz 1.2.3. 编译并安装 cd $HOME/build/nginx- ./configure \\ --prefix=/etc/nginx \\ --sbin-path=/usr/sbin/nginx \\ --conf-path=/etc/nginx/nginx.conf \\ ... # make && make install 1.2.4. 配置项 1.2.4.1. 通用配置项 配置选项 说明 --prefix= nginx安装的根路径，所有其他的路径都要依赖与该选项 --sbin-path= nginx二进制文件的路径，如果没有指定则会依赖于--prefix --conf-path= 如果在命令行中没有指定配置文件，则通过该配置项去查找配置文件 --error-log-path= 指定错误文件的路径 --pid-path= 指定的文件将会写入nginx master进程的pid，通常在/var/run下 --lock-path= 共享存储器互斥锁文件的路径 --user= worker进程运行的用户 --group= worker进程运行的组 --with-file-aio 启动异步I/O --with-debug 启用调试日志，生产环境不推荐配置 1.2.4.2. 优化配置项 配置选项 说明 --with-cc= 如果想设置一个不在默认PATH下的C编译器 --with-cpp= 设置C预处理器的相应路径 --with-cc-opt= 指定必要的include文件路径 --with-ld-opt= 包含连接器库的路径和运行路径 --with-cpu-opt= 通过该选项为特定的CPU构建nginx 1.2.4.3. http模块的配置项 配置选项 说明 --without-http-cache 在使用upstream模块时，nginx能够配置本地缓存内容，该选项可以禁用缓存 --with-http_perl_module nginx配置能够扩展使用perl代码。该项启用这个模块，但会降低性能 --with-perl_modules_path= 对于额外嵌入的perl模块，该选项指定该perl解析器的路径 --with-perl= 如果在默认的路径中找不到perl则指定perl（5.6版本以上）的路径 --http-log-path= http访问日志的默认路径 --http-client-body-temp-path= 从客户端收到请求后，该项用于作为请求体临时存放的目录 --http-proxy-temp-path= 在使用代理后，通过该项设置存放临时文件路径 --http-fastcgi-temp-path= 设置FastCGI临时文件的目录 --http-uwsgi-temp-path= 设置uWSGI临时文件的目录 --http-scgi-temp-path= 设置SCGI临时文件的目录 1.2.4.4. 其他模块额外配置项 默认没有安装这些模块，可以通过--with-_module来启用相应的模块功能。 配置选项 说明 --with-http_ssl_module 如果需要对流量进行加密，可以使用该选项，再URLs中开始部分将会是https(需要OpenSSL库) --with-http_realip_module 如果nginx在七层负载均衡器或者其他设备之后，它们将Http头中的客户端IP地址传递，则需要启用该模块，再多个客户处于一个IP地址的情况下使用 --with-http_addition_module 该模块作为输出过滤器，使能够在请求经过一个location前或后时在该location本身添加内容 --with-http_xslt_module 该模块用于处理XML响应转换，基于一个或多个XSLT格式 --with-http_image_filter_module 该模块被作为图像过滤器使用，在将图像投递到客户之前进行处理（需要libgd库） --with-http_geoip_module 使用该模块，能够设置各种变量以便在配置文件中的区段使用，基于地理位置查找客户端IP地址 --with-http_sub_module 该模块实现替代过滤，在响应中用一个字符串替代另一个字符串 --with-heep_dav_module 启用这个模块将激活使用WebDAV的配置指令。 --with-http_flv_module 如果需要提供Flash流媒体视频文件，那么该模块将会提供伪流媒体 --with-http_mp4_module 这个模块支持H.264/AAC文件伪流媒体 --with-http_gzip_static_module 当被调用的资源没有.gz结尾格式的文件时，如果想支持发送预压缩版本的静态文件，那么使用该模块 --with-http_gunzip_module 对于不支持gzip编码的客户，该模块用于为客户解压缩预压缩内容 --with-http_random_index_module 如果你想提供从一个目录中随机选择文件的索引文件，那么该模块需要激活 --with-http_secure_link_module 该模块提供一种机制，它会将一个哈希值链接到一个URL中，因此只有那些使用正确密码能够计算链接 --with-http_stub_status_module 启用这个模块后会收集Nginx自身的状态信息。输出的状态信息可以使用RRDtool或类似的东西绘制成图 2. 配置 配置文件一般为/etc/nginx/nginx.conf或/usr/local/nginx/conf/nginx.conf。 2.1. 基本配置格式 { ; } 每一个指令行由分号结束，大括号{}表示一个新的上下文。 2.2. Nginx全局配置参数 全局配置指令 模块 配置项 说明 main模块 user 配置worker进程的用户和组，如果忽略group，则group等于指定的用户的所属组 worker_processes 指定worker进程的启动数量，可将其设置为可用的CPU内核数，若为auto为自动检测 error_log 所有错误的写入文件，第二个参数指定错误的级别（debug，info，notice，warn，error，crit，alert，emerg） pid 设置主进程IP的文件 events模块 use 用于设置使用什么样的连接方法 worker_connections 用于配置一个工作进程能够接受的并发连接最大数。包括客户连接和向上游服务器的连接。 2.3. 使用include文件 include文件可以在任何地方以增强配置文件的可读性，使用include文件要确保被包含文件自身正确的nginx语法，即配置指令和块，然后指定这些文件的路径。 include /etc/nginx/mime.types; 若使用通配符则表示通配的多个文件，若没有给定全路径则依据主配置文件路径进行搜索。 include /etc/nginx/conf.d/*.conf 测试配置文件(包括include的配置文件)语法： nginx -t -c {path-to-nginx.conf} 2.4. 配置说明 2.4.1. main模块 #main模块类似main函数包含其他子模块，非模块配置项(包括模块内)分号结尾，子模块配置花括号结尾 user nobady; #一般按默认设置 pid /var/run/nginx.pid; #进程标识符存放路径，一般按默认设置 worker_processes auto; #nginx对外提供web服务时的worder进程数，可将其设置为可用的CPU内核数，auto为自动检测 worker_rlimit_nofile 100000; # 更改worker进程的最大打开文件数限制 error_log logs/error.log info; #错误日志存放路径 keepalive_timeout 60; #keepalive_timeout 60; events{ #见events模块 } http{ #见http模块 server{ ... location /{ } } } mail{ #见mail模块 } 2.4.2. events模块 events { worker_connections 2048; #设置可由一个worker进程同时打开的最大连接数 multi_accept on; #告诉nginx收到一个新连接通知后接受尽可能多的连接 use epoll; #设置用于复用客户端线程的轮询方法。Linux 2.6+：使用epoll；*BSD：使用kqueue。 } 2.4.3. http模块 http { #http模块 server { #server模块，http服务上的虚拟主机， server 当做对应一个域名进行的配置 listen 80; #配置监听端口 server_name www.linuxidc.com; #配置访问域名 access_log logs/linuxidc.access.log main; #指定日志文件的存放路径 index index.html; #默认访问页面 root /var/www/androidj.com/htdocs; # root 是指将本地的一个文件夹作为所有 url 请求的根路径 upstream backend { #反向代理的后端机器，实现负载均衡 ip_hash; #指明了我们均衡的方式是按照用户的 ip 地址进行分配 server backend1.example.com; server backend2.example.com; server backend3.example.com; server backend4.example.com; } location / { #location 是在一个域名下对更精细的路径进行配置 proxy_pass http://backend; #反向代理到后端机器 } } server { listen 80; server_name www.Androidj.com; access_log logs/androidj.access.log main; location / { index index.html; root /var/www/androidj.com/htdocs; } } } 2.4.4. mail模块 mail { auth_http 127.0.0.1:80/auth.php; pop3_capabilities \"TOP\" \"USER\"; imap_capabilities \"IMAP4rev1\" \"UIDPLUS\"; server { listen 110; protocol pop3; proxy on; } server { listen 25; protocol smtp; proxy on; smtp_auth login plain; xclient off; } } Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-09-23 17:56:15 "},"nginx/nginx-proxy.html":{"url":"nginx/nginx-proxy.html","title":"Nginx作为反向代理","keywords":"","body":"1. 反向代理简介 Nginx可以作为反向代理，接收客户端的请求，并向上游服务器发起新的请求。该请求可以根据客户端请求的URI，客户机参数或其他逻辑进行拆分，原始URL中的任何部分可以以这种方式进行转换。 1.1. 代理模块指令 指令 说明 proxy_connect_timeout Nginx从接受到请求到连接至上游服务器的最长等待时间 proxy_cookie_domain 替代从上游服务器来的Set-Cookie头的域domain proxy_cookie_path 替代从上游服务器来的Set-Cookie头的path属性 proxy_headers_hash_bucket_size 头名字的最大值 proxy_headers_hash_max_size 从上游服务器接收到头的总大小 proxy_hide_header 不应该传递给客户端头的列表 proxy_http_version 用于通上游服务器通信的Http协议版本 proxy_ignore_client_abort 如果设置为ON，那么客户端放弃连接后，nginx将不会放弃同上游服务器的连接 proxy_ignore_headers 当处理来自上游服务器的响应时，设置哪些头可以被忽略 proxy_intercept_errors 如果启用该选项，Nginx将会显示配置的error_page错误，而不是来自于上游服务器的直接响应 proxy_max_temp_file_size 在写入内存缓冲区时响应与内存不匹配时使用时，给出溢出文件的最大值 proxy_pass 指定请求被传递到的上游服务器，格式为URL proxy_pass_header 覆盖掉在proxy_hide_header指令中设置的头，允许这些头传递到客户端 proxy_pass_request_body 如果设置为off，将会阻止请求体传递到客户端 proxy_pass_request_headers 如果设置为on,则阻止请求头发送到上游服务器 proxy_read_timeout 给出连接关闭前从上游服务器两次成功的读操作耗时，如果上游服务器处理请求比较慢，那么该值需设置较高些 proxy_redirect 重写来自于上游服务器的Location和Refresh头 proxy_send_timeout 给出连接关闭前从上游服务器两次成功的写操作耗时，如果上游服务器处理请求比较慢，那么该值需设置较高些 proxy_set_body 发送到上游服务器的请求体可能会被该指令的设置值修改 proxy_set_header 重写发送到上游服务器头的内容，也可以通过将某种头的值设置为空字符，而不是发送某种头的方法实现 proxy_temp_file_write_size 在同一时间内限制缓冲到一个临时文件的数据量，以使得Nginx不会过长地阻止单个请求 proxy_temp_path 设定临时文件的缓冲，用于缓冲从上游服务器来的文件，可以设定目录的层次 1.2. upstream模块 upstream指令将会启用一个新的配置区域，在该区域定义了一组上游服务器，这些服务器可以被设置为不同的权重（权重高的服务器将会被Nginx传递越多的连接）。 指令 说明 ip_hash 通过IP地址的哈希值确保客户端均匀地连接所有的服务器，键值基于C类地址 keepalive 每一个worker进程缓存的到上游服务器的连接数。再使用Http连接时，proxy_http_verison设置1.1，并将proxy_set_header设置为Connection \"\" least_conn 激活负载均衡算法，将请求发送到活跃连接数最少的那台服务器 server 为upstream定义一个服务器地址（带有端口号的域名、IP地址，或者是UNIX套接字）和一个可选的参数，参数如下：weight：设置一个服务器的优先级优于其他服务器。max_fails：设置在fail_timeout时间之内尝试对一个服务器连接的最大次数，如果超过这个次数，那么就会被标记为down。fail_timeout：在这个指定的时间内服务器必须提供响应，如果在这个时间内没有收到响应，那么服务器就会被标记为down状态。backup：一旦其他服务器宕机，那么有该标记的机器就会接收请求。down：标记为一个服务器不再接受任何请求。 1.2.1. 负载均衡算法 upstream模块能够使用轮询、IP hash和最少连接数三种负载均衡算法之一来选择哪个上游服务器将会被在下一步中连接。 1.2.1.1. 轮询 默认情况使用轮询，不需要配置指令来设置，该算法选择下一个服务器，基于先前选择，再配置文件中哪一个是下一个服务器，以及每个服务器的负载。轮询算法是基于在队列中谁是下一个的原理确保将访问量均匀的分配给每一个上游服务器。 1.2.1.2. IP 哈希 通过ip_hash指令激活使用，从而将某些IP地址映射到同一个上游服务器。 1.2.1.3. 最少连接数 通过least_conn指令启用，该算法通过选择一个活跃的最少连接数服务器，然后将负载均匀分配给上游服务器。如果上游服务器的处理器能力不同，那么可以为server指令使用weight来指示说明。该算法将考虑到不同服务器的加权最小连接数。 2. Upstream服务器类型 上游服务器是Ngixn代理连接的一个服务器，可以是物理机或虚拟机。 2.1. 单个upstream服务器 指令try_files(包括http core模块内)意味着按顺序尝试，直到找到一个匹配为止。Nginx将会投递与客户端给定URI匹配的任何文件，如果没有找到任何配置文件，将会把请求代理到Apache作进一步处理。 2.2. 多个upstream服务器 Nginx将会通过轮询的方式将连续请求传递给3个上游服务器。这样应用程序不会过载。 图片 - 这里写图片描述 3. 负载均衡特别说明 如果客户端希望总是访问同一个上游服务器，可以使用ip_hash指令； 如果请求响应时间长短不一，可以使用least_conn指令； 默认为轮询。 Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-09-23 18:02:10 "},"nginx/nginx-http.html":{"url":"nginx/nginx-http.html","title":"Nginx http服务器","keywords":"","body":"1. Nginx的系统架构 Nginx包含一个单一的master进程和多个worker进程，每个进程都是单进程，并且设计为同时处理成千上万个连接。 worker进程是处理连接的地方，Nginx使用了操作系统事件机制来快速响应这些请求。 master进程负责读取配置文件、处理套接字、派生worker进程、打开日志文件和编译嵌入式的perl脚本。master进程是一个可以通过处理信号量来管理请求的进程。 worker进程运行在一个忙碌的事件循环处理中，用于处理进入的连接。每一个nginx模块被构筑在worker中。任何请求处理、过滤、处理代理的连接和更多操作都在worker中完成。 如果没有阻塞worker进程的进程（例如磁盘I/O），那么需要配置的worker进程要多于CPU内核数，以便处理负载。 2. Http核心模块 2.1.1. server 指令server开始一个新的上下文（context）。 http server指令 指令 说明 port_in_redirect 确认nginx是否对端口指定重定向 server 创建一个新的配置区域，定义一个虚拟主机。listen指令指定IP和端口；server_name列举用于匹配的Host头值 server_name 配置用于响应请求的虚拟主机名称 server_name_in_redirect server_tokens 在错误信息中禁止发送nginx的版本号和server响应头 2.1.2. 日志格式 参数 说明 示例 $remote_addr 客户端地址 211.28.65.253 $remote_user 客户端用户名称 -- $time_local 访问时间和时区 18/Jul/2012:17:00:01 +0800 $request 请求的URI和HTTP协议 \"GET /article-10000.html HTTP/1.1\" $http_host 请求地址，即浏览器中你输入的地址（IP或域名） www.it300.com192.168.100.100 $status HTTP请求状态 200 $upstream_status upstream状态 200 $body_bytes_sent 发送给客户端文件内容大小 1547 $http_referer url跳转来源 https://www.baidu.com/ $http_user_agent 用户终端浏览器等信息 \"Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; SV1; GTB7.0; .NET4.0C; $ssl_protocol SSL协议版本 TLSv1 $ssl_cipher 交换数据中的算法 RC4-SHA $upstream_addr 后台upstream的地址，即真正提供服务的主机地址 10.10.10.100:80 $request_time 整个请求的总时间 0.205 $upstream_response_time 请求过程中，upstream响应时间 0.002 日志切割 # vim /etc/logrotate.d/nginx /usr/local/nginx/logs/*.log{ #指定转储周期为每天 daily #保留30个备份 rotate 30 #需要压缩 delaycompress #YYYYMMDD日期格式 dateext #忽略错误 missingok #如果日志为空则不做轮询 notifempty #只为整个日志组运行一次的脚本 sharedscripts #日志轮询后执行的脚本 postrotate service nginx reload endscript } Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-09-23 17:57:42 "},"keepalived/keepalived-introduction.html":{"url":"keepalived/keepalived-introduction.html","title":"Keepalived简介","keywords":"","body":"1. Keepalived简介 1.1. 概述 Keepalived一个基于VRRP协议来实现的LVS服务高可用方案，可以利用其来避免单点故障。一个LVS服务会有2台服务器运行Keepalived，一台为主服务器（MASTER），一台为备份服务器（BACKUP），但是对外表现为一个虚拟IP，主服务器会发送特定的消息给备份服务器，当备份服务器收不到这个消息的时候，即主服务器宕机的时候， 备份服务器就会接管虚拟IP，继续提供服务，从而保证了高可用性。 1.2. keepalived的作用 Keepalived的作用是检测服务器的状态，如果有一台web服务器死机，或工作出现故障，Keepalived将检测到，并将有故障的服务器从系统中剔除，同时使用其他服务器代替该服务器的工作，当服务器工作正常后Keepalived自动将服务器加入到服务器群中。 2. 如何实现Keepalived 2.1. 基于VRRP协议的理解 Keepalived是以VRRP协议为实现基础的，VRRP全称Virtual Router Redundancy Protocol，即虚拟路由冗余协议。 虚拟路由冗余协议，可以认为是实现路由器高可用的协议，即将N台提供相同功能的路由器组成一个路由器组，这个组里面有一个master和多个backup，master上面有一个对外提供服务的vip（该路由器所在局域网内其他机器的默认路由为该vip），master会发组播，当backup收不到vrrp包时就认为master宕掉了，这时就需要根据VRRP的优先级来选举一个backup当master。这样的话就可以保证路由器的高可用了。 keepalived主要有三个模块，分别是core、check和vrrp。core模块为keepalived的核心，负责主进程的启动、维护以及全局配置文件的加载和解析。check负责健康检查，包括常见的各种检查方式。vrrp模块是来实现VRRP协议的。 2.2. 基于TCP/IP协议的理解 Layer3,4&7工作在IP/TCP协议栈的IP层，TCP层，及应用层,原理分别如下： Layer3： Keepalived使用Layer3的方式工作式时，Keepalived会定期向服务器群中的服务器发送一个ICMP的数据包（既我们平时用的Ping程序）,如果发现某台服务的IP地址没有激活，Keepalived便报告这台服务器失效，并将它从服务器群中剔除，这种情况的典型例子是某台服务器被非法关机。Layer3的方式是以服务器的IP地址是否有效作为服务器工作正常与否的标准。 Layer4: 如果您理解了Layer3的方式，Layer4就容易了。Layer4主要以TCP端口的状态来决定服务器工作正常与否。如web server的服务端口一般是80，如果Keepalived检测到80端口没有启动，则Keepalived将把这台服务器从服务器群中剔除。 Layer7： Layer7就是工作在具体的应用层了，比Layer3,Layer4要复杂一点，在网络上占用的带宽也要大一些。Keepalived将根据用户的设定检查服务器程序的运行是否正常，如果与用户的设定不相符，则Keepalived将把服务器从服务器群中剔除。 3. Keepalived选举策略 3.1. 选举策略 首先，每个节点有一个初始优先级，由配置文件中的priority配置项指定，MASTER节点的priority应比BAKCUP高。运行过程中keepalived根据vrrp_script的weight设定，增加或减小节点优先级。规则如下： 当weight > 0时，vrrp_script script脚本执行返回0(成功)时优先级为priority + weight, 否则为priority。当BACKUP发现自己的优先级大于MASTER通告的优先级时，进行主从切换。 当weight 3.2. priority和weight的设定 主从的优先级初始值priority和变化量weight设置非常关键，配错的话会导致无法进行主从切换。比如，当MASTER初始值定得太高，即使script脚本执行失败，也比BACKUP的priority + weight大，就没法进行VIP漂移了。 所以priority和weight值的设定应遵循: abs(MASTER priority - BAKCUP priority) Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-09-23 17:44:10 "},"keepalived/install-keepalived.html":{"url":"keepalived/install-keepalived.html","title":"Keepalived的安装与配置","keywords":"","body":"1. Keepalived的安装 1.1. yum install方式 yum install -y keepalived 1.2. 安装包编译方式 更多安装包参考：http://www.keepalived.org/download.html wget http://www.keepalived.org/software/keepalived-2.0.7.tar.gz tar zxvf keepalived-2.0.7.tar.gz cd keepalived-2.0.7 ./configure --bindir=/usr/bin --sbindir=/usr/sbin --sysconfdir=/etc --mandir=/usr/share make && make install 2. 常用配置 keepalived配置文件路径：/etc/keepalived/keepalived。 2.1. MASTER（主机配置） global_defs { router_id proxy-keepalived } vrrp_script check_nginx { script \"/etc/keepalived/scripts/check_nginx.sh\" interval 3 weight 2 } vrrp_instance VI_1 { state MASTER interface eth2 virtual_router_id 15 priority 100 advert_int 1 authentication { auth_type PASS auth_pass xxx } track_script { check_nginx } virtual_ipaddress { 180.101.115.139 218.98.38.29 } nopreempt notify_master \"/etc/keepalived/keepalived_notify.sh master\" notify_backup \"/etc/keepalived/keepalived_notify.sh backup\" notify_fault \"/etc/keepalived/keepalived_notify.sh fault\" notify_stop \"/etc/keepalived/keepalived_notify.sh stop\" } 2.2. BACKUP（备机配置） global_defs { router_id proxy-keepalived } vrrp_script check_nginx { script \"/etc/keepalived/scripts/check_nginx.sh\" interval 3 weight 2 } vrrp_instance VI_1 { state BACKUP interface eth2 virtual_router_id 15 priority 99 advert_int 1 authentication { auth_type PASS auth_pass xxx } track_script { check_nginx } virtual_ipaddress { 180.101.115.139 218.98.38.29 } nopreempt notify_master \"/etc/keepalived/keepalived_notify.sh master\" notify_backup \"/etc/keepalived/keepalived_notify.sh backup\" notify_fault \"/etc/keepalived/keepalived_notify.sh fault\" notify_stop \"/etc/keepalived/keepalived_notify.sh stop\" } 2.3. 注意事项 1、指定Nginx健康检测脚本：/etc/keepalived/scripts/check_nginx.sh 2、主备配置差别主要为（建议这么配置）： 主机:(state MASTER;priority 100) 备机：(state BACKUP;priority 99) 非抢占：nopreempt 或者： 主机:(state BACKUP;priority 100) 备机：(state BACKUP;priority 100) 默认抢占 3、指定VIP virtual_ipaddress { 180.101.115.139 218.98.38.29 } 4、可以指定为非抢占：nopreempt，即priority高不会抢占已经绑定VIP的机器。 5、制定绑定IP的网卡： interface eth2 6、可以指定keepalived状态变化通知 notify_master \"/etc/keepalived/keepalived_notify.sh master\" notify_backup \"/etc/keepalived/keepalived_notify.sh backup\" notify_fault \"/etc/keepalived/keepalived_notify.sh fault\" notify_stop \"/etc/keepalived/keepalived_notify.sh stop\" 7、virtual_router_id 15值，主备值一致，但建议不应与集群中其他Nginx机器上的相同 3. 常用脚本 3.1. Nginx健康检测脚本 在Nginx配置目录下（/etc/nginx/conf.d/）增加health.conf的配置文件,该配置文件用于配置Nginx health的接口。 server { listen 80 default_server; server_name localhost; default_type text/html; return 200 'Health'; } Nginx健康检测脚本：/etc/keepalived/scripts/check_nginx.sh 3.1.1. 检查接口调用是否为200 #!/bin/sh set -x timeout=30 #指定默认30秒没返回200则为非健康，该值可根据实际调整 if [ -n ${timeout} ];then httpcode=`curl -sL -w %{http_code} -m ${timeout} http://localhost -o /dev/null` else httpcode=`curl -sL -w %{http_code} http://localhost -o /dev/null` fi if [ ${httpcode} -ne 200 ];then echo `date`': nginx is not healthy, return http_code is '${httpcode} >> /etc/keeperalived/keepalived.log killall keepalived exit 1 else exit 0 fi 3.1.2. 检查Nginx进程是否运行 #!/bin/sh if [ `ps -C nginx --no-header |wc -l` -eq 0 ];then echo \"$(date) nginx pid not found\">>/etc/keepalived/keepalived.log killall keepalived fi 3.2. Keepalived状态通知脚本 #!/bin/bash set -x warn_receiver=$1 ip=$(ifconfig bond0|grep inet |awk '{print $2}') warningInfo=\"${ip}_keepalived_changed_status_to_$1\" warn-report --user admin --key=xxxx --target=${warn_receiver} ${warningInfo} echo $(date) $1 >> /etc/keepalived/status 说明： ip获取本机IP，本例中IP获取是bond0的IP，不同机器网卡名称不同需要修改为对应网卡名称。 告警工具根据自己指定。 4. 常用命令 4.1. 查看当前VIP在哪个节点上 # 查看VIP是否在筛选结果中 ip addr show|grep \"scope global\" # 或者 ip addr show|grep {vip} 4.2. 查看keepalived的日志 tail /var/log/messages 4.3. 抓包命令 # 抓包 tcpdump -nn vrrp # 可以用这条命令来查看该网络中所存在的vrid tcpdump -nn -i any net 224.0.0.0/8 4.4. VIP操作 # 解绑VIP ip addr del dev # 绑定VIP ip addr add dev 4.5. keepalived 切 VIP 例如将 A 机器上的 VIP 迁移到B 机器上。 4.5.1. 停止keepalived服务 停止被迁移的机器（A机器）的keepalived服务。 systemctl stop keepalived 4.5.2. 查看日志 解绑 A机器 VIP的日志 Sep 19 14:28:09 localhost systemd: Stopping LVS and VRRP High Availability Monitor... Sep 19 14:28:09 localhost Keepalived[45705]: Stopping Sep 19 14:28:09 localhost Keepalived_vrrp[45707]: VRRP_Instance(twemproxy) sent 0 priority Sep 19 14:28:09 localhost Keepalived_vrrp[45707]: VRRP_Instance(twemproxy) removing protocol VIPs. Sep 19 14:28:09 localhost Keepalived_healthcheckers[45706]: Stopped Sep 19 14:28:10 localhost Keepalived_vrrp[45707]: Stopped Sep 19 14:28:10 localhost Keepalived[45705]: Stopped Keepalived v1.3.5 (03/19,2017), git commit v1.3.5-6-g6fa32f2 Sep 19 14:28:10 localhost systemd: Stopped LVS and VRRP High Availability Monitor. Sep 19 14:28:10 localhost ntpd[1186]: Deleting interface #10 bond0, 192.168.99.9#123, interface stats: received=0, sent=0, dropped=0, active_time=6755768 secs 绑定 B 机器 VIP的日志 Sep 17 17:20:25 localhost systemd: Starting LVS and VRRP High Availability Monitor... Sep 17 17:20:26 localhost Keepalived[34566]: Starting Keepalived v1.3.5 (03/19,2017), git commit v1.3.5-6-g6fa32f2 Sep 17 17:20:26 localhost Keepalived[34566]: Opening file '/etc/keepalived/keepalived.conf'. Sep 17 17:20:26 localhost Keepalived[34568]: Starting Healthcheck child process, pid=34569 Sep 17 17:20:26 localhost Keepalived[34568]: Starting VRRP child process, pid=34570 Sep 17 17:20:26 localhost Keepalived_vrrp[34570]: Registering Kernel netlink reflector Sep 17 17:20:26 localhost Keepalived_vrrp[34570]: Registering Kernel netlink command channel Sep 17 17:20:26 localhost Keepalived_vrrp[34570]: Registering gratuitous ARP shared channel Sep 17 17:20:26 localhost Keepalived_vrrp[34570]: Opening file '/etc/keepalived/keepalived.conf'. Sep 17 17:20:26 localhost Keepalived_vrrp[34570]: Truncating auth_pass to 8 characters Sep 17 17:20:26 localhost Keepalived_vrrp[34570]: VRRP_Instance(twemproxy) removing protocol VIPs. Sep 17 17:20:26 localhost Keepalived_vrrp[34570]: Using LinkWatch kernel netlink reflector... Sep 17 17:20:26 localhost Keepalived_vrrp[34570]: VRRP_Instance(twemproxy) Entering BACKUP STATE Sep 17 17:20:26 localhost Keepalived_vrrp[34570]: VRRP sockpool: [ifindex(4), proto(112), unicast(0), fd(10,11)] Sep 17 17:20:26 localhost systemd: Started LVS and VRRP High Availability Monitor. Sep 17 17:20:26 localhost kernel: IPVS: Registered protocols (TCP, UDP, SCTP, AH, ESP) Sep 17 17:20:26 localhost kernel: IPVS: Connection hash table configured (size=4096, memory=64Kbytes) Sep 17 17:20:26 localhost kernel: IPVS: Creating netns size=2192 id=0 Sep 17 17:20:26 localhost kernel: IPVS: Creating netns size=2192 id=1 Sep 17 17:20:26 localhost kernel: IPVS: ipvs loaded. Sep 17 17:20:26 localhost Keepalived_healthcheckers[34569]: Opening file '/etc/keepalived/keepalived.conf'. Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-09-23 17:44:10 "},"keepalived/keepalived-conf.html":{"url":"keepalived/keepalived-conf.html","title":"Keepalived的配置详解","keywords":"","body":"详细配置说明 keepalived只有一个配置文件/etc/keepalived/keepalived.conf。 里面主要包括以下几个配置区域，分别是: global_defs static_ipaddress static_routes vrrp_script vrrp_instance virtual_server 1. global_defs区域 主要是配置故障发生时的通知对象以及机器标识。 global_defs { notification_email { # notification_email 故障发生时给谁发邮件通知 a@abc.com b@abc.com ... } notification_email_from alert@abc.com # notification_email_from 通知邮件从哪个地址发出 smtp_server smtp.abc.com # smpt_server 通知邮件的smtp地址 smtp_connect_timeout 30 # smtp_connect_timeout 连接smtp服务器的超时时间 enable_traps # enable_traps 开启SNMP陷阱（Simple Network Management Protocol） router_id host163 # router_id 标识本节点的字条串，通常为hostname，但不一定非得是hostname。故障发生时，邮件通知会用到。 } 2. static_ipaddress和static_routes区域[可忽略] static_ipaddress和static_routes区域配置的是是本节点的IP和路由信息。如果你的机器上已经配置了IP和路由，那么这两个区域可以不用配置。其实，一般情况下你的机器都会有IP地址和路由信息的，因此没必要再在这两个区域配置。 static_ipaddress { 10.210.214.163/24 brd 10.210.214.255 dev eth0 ... } static_routes { 10.0.0.0/8 via 10.210.214.1 dev eth0 ... } 3. vrrp_script区域 用来做健康检查的，当时检查失败时会将vrrp_instance的priority减少相应的值。 vrrp_script chk_http_port { script \" 4. vrrp_instance和vrrp_sync_group区域 vrrp_instance用来定义对外提供服务的VIP区域及其相关属性。 vrrp_rsync_group用来定义vrrp_intance组，使得这个组内成员动作一致。 vrrp_sync_group VG_1 { #监控多个网段的实例 group { inside_network # name of vrrp_instance (below) outside_network # One for each moveable IP. ... } notify_master /path/to_master.sh # notify_master表示切换为主机执行的脚本 notify_backup /path/to_backup.sh # notify_backup表示切换为备机师的脚本 notify_fault \"/path/fault.sh VG_1\" # notify_fault表示出错时执行的脚本 notify /path/notify.sh # notify表示任何一状态切换时都会调用该脚本，且在以上三个脚本执行完成之后进行调用 smtp_alert # smtp_alert 表示是否开启邮件通知（用全局区域的邮件设置来发通知） } vrrp_instance VI_1 { state MASTER # state MASTER或BACKUP，当其他节点keepalived启动时会将priority比较大的节点选举为MASTER，因此该项其实没有实质用途。 interface eth0 # interface 节点固有IP（非VIP）的网卡，用来发VRRP包 use_vmac dont_track_primary # use_vmac 是否使用VRRP的虚拟MAC地址，dont_track_primary 忽略VRRP网卡错误（默认未设置） track_interface {# track_interface 监控以下网卡，如果任何一个不通就会切换到FALT状态。（可选项） eth0 eth1 } #mcast_src_ip 修改vrrp组播包的源地址，默认源地址为master的IP mcast_src_ip lvs_sync_daemon_interface eth1 #lvs_sync_daemon_interface 绑定lvs syncd的网卡 garp_master_delay 10 # garp_master_delay 当切为主状态后多久更新ARP缓存，默认5秒 virtual_router_id 1 # virtual_router_id 取值在0-255之间，用来区分多个instance的VRRP组播， 同一网段中virtual_router_id的值不能重复，否则会出错 priority 100 #priority用来选举master的，根据服务是否可用，以weight的幅度来调整节点的priority，从而选取priority高的为master，该项取值范围是1-255（在此范围之外会被识别成默认值100） advert_int 1 # advert_int 发VRRP包的时间间隔，即多久进行一次master选举（可以认为是健康查检时间间隔） authentication { # authentication 认证区域，认证类型有PASS和HA（IPSEC），推荐使用PASS（密码只识别前8位） auth_type PASS #认证方式 auth_pass 12345678 #认证密码 } virtual_ipaddress { # 设置vip 10.210.214.253/24 brd 10.210.214.255 dev eth0 192.168.1.11/24 brd 192.168.1.255 dev eth1 } virtual_routes { # virtual_routes 虚拟路由，当IP漂过来之后需要添加的路由信息 172.16.0.0/12 via 10.210.214.1 192.168.1.0/24 via 192.168.1.1 dev eth1 default via 202.102.152.1 } track_script { chk_http_port } nopreempt # nopreempt 允许一个priority比较低的节点作为master，即使有priority更高的节点启动 preempt_delay 300 # preempt_delay master启动多久之后进行接管资源（VIP/Route信息等），并提是没有nopreempt选项 debug notify_master| notify_backup| notify_fault| notify| smtp_alert } 5. virtual_server_group和virtual_server区域 virtual_server_group一般在超大型的LVS中用到，一般LVS用不到这东西。 virtual_server IP Port { delay_loop # delay_loop 延迟轮询时间（单位秒） lb_algo rr|wrr|lc|wlc|lblc|sh|dh # lb_algo 后端调试算法（load balancing algorithm） lb_kind NAT|DR|TUN # lb_kind LVS调度类型NAT/DR/TUN persistence_timeout #会话保持时间 persistence_granularity #lvs会话保持粒度 protocol TCP #使用的协议 ha_suspend virtualhost # virtualhost 用来给HTTP_GET和SSL_GET配置请求header的 alpha omega quorum hysteresis quorum_up| quorum_down| sorry_server #备用机，所有realserver失效后启用 real_server{ # real_server 真正提供服务的服务器 weight 1 # 默认为1,0为失效 inhibit_on_failure #在服务器健康检查失效时，将其设为0，而不是直接从ipvs中删除 notify_up| # real server宕掉时执行的脚本 notify_down| # real server启动时执行的脚本 # HTTP_GET|SSL_GET|TCP_CHECK|SMTP_CHECK|MISC_CHECK TCP_CHECK { connect_timeout 3 #连接超时时间 nb_get_retry 3 #重连次数 delay_before_retry 3 #重连间隔时间 connect_port 23 #健康检查的端口的端口 bindto } HTTP_GET|SSL_GET { url {# 检查url，可以指定多个 path # path 请求real serserver上的路径 digest # 用genhash算出的摘要信息 status_code # 检查的http状态码 } connect_port # connect_port 健康检查，如果端口通则认为服务器正常 connect_timeout # 超时时长 nb_get_retry # 重试次数 delay_before_retry # 下次重试的时间延迟 } SMTP_CHECK { host { connect_ip connect_port #默认检查25端口 bindto } connect_timeout 5 retry 3 delay_before_retry 2 helo_name | #smtp helo请求命令参数，可选 } MISC_CHECK { misc_path | #外部脚本路径 misc_timeout #脚本执行超时时间 misc_dynamic #如设置该项，则退出状态码会用来动态调整服务器的权重，返回0 正常，不修改；返回1， #检查失败，权重改为0；返回2-255，正常，权重设置为：返回状态码-2 } } } Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-09-23 17:44:10 "}}